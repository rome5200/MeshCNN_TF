{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d1035b36-69ce-45f6-a288-4936a930c542",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\anaconda3\\envs\\project2025\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "# 기본 패키지 임포트\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import trimesh, pickle\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.font_manager as fm\n",
    "\n",
    "# 디바이스 설정 (GPU 사용 가능 시 GPU로 설정)\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(\"Using device:\", device)\n",
    "torch.backends.cudnn.benchmark = True\n",
    "torch.backends.cudnn.enabled = True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "70d996f3-807e-4bcf-9a03-d51f9b850be1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "class LungNoduleDataset(Dataset):\n",
    "    def __init__(self, data_dir, split='train'):\n",
    "        self.mesh_files = []\n",
    "        self.face_labels = []   # 각 메쉬의 face 레이블 경로 또는 데이터\n",
    "        self.class_labels = []  # 결절 존재 유무 (0 또는 1)\n",
    "        # 데이터 디렉터리에서 파일 목록 구성\n",
    "        mesh_dir = os.path.join(data_dir, split, \"mesh\")\n",
    "        label_dir = os.path.join(data_dir, split, \"label\")  # face별 레이블 파일 (예: .npy 또는 .txt)\n",
    "        for fname in os.listdir(mesh_dir):\n",
    "            if fname.endswith('.obj') or fname.endswith('.stl') or fname.endswith('.ply'):\n",
    "                mesh_path = os.path.join(mesh_dir, fname)\n",
    "                label_path = os.path.join(label_dir, fname.split('.')[0] + \"_label.npy\")\n",
    "                self.mesh_files.append(mesh_path)\n",
    "                if os.path.exists(label_path):\n",
    "                    face_label = np.load(label_path)  # face 레이블 (예: 0/1 값의 배열)\n",
    "                else:\n",
    "                    face_label = None\n",
    "                self.face_labels.append(face_label)\n",
    "                # 클래스 레이블: face_label에 1이 하나라도 있으면 1 (결절 있음), 아니면 0\n",
    "                class_label = 1 if (face_label is not None and face_label.sum() > 0) else 0\n",
    "                self.class_labels.append(class_label)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.mesh_files)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        # 캐시 디렉토리 경로 (문자열로 지정)\n",
    "        CACHE_DIR = \"C:/Users/konyang/Desktop/MeshCNN_TF/data/cache/train\"\n",
    "        os.makedirs(CACHE_DIR, exist_ok=True)  # 디렉토리가 없다면 생성\n",
    "\n",
    "        # 메쉬 파일 경로와 캐시 파일 경로 생성\n",
    "        mesh_path = self.mesh_files[idx]\n",
    "        mesh_stem = os.path.splitext(os.path.basename(mesh_path))[0]  # 파일명에서 확장자 제거\n",
    "        cache_path = os.path.join(CACHE_DIR, mesh_stem + \".pkl\")\n",
    "\n",
    "        # 캐시가 있다면 로드\n",
    "        if os.path.exists(cache_path):\n",
    "            with open(cache_path, 'rb') as f:\n",
    "                return pickle.load(f)\n",
    "        \n",
    "        # 1. 메쉬 파일 로드\n",
    "        mesh = trimesh.load(self.mesh_files[idx])\n",
    "        vertices = np.array(mesh.vertices)        # (V, 3) 배열\n",
    "        faces = np.array(mesh.faces)              # (F, 3) 배열\n",
    "        face_normals = np.array(mesh.face_normals)  # 각 face의 법선 벡터\n",
    "        face_labels = self.face_labels[idx]\n",
    "        \n",
    "        # 2. 간선 및 간선->면 매핑 생성\n",
    "        edge_to_faces = {}\n",
    "        for f_idx, face in enumerate(faces):\n",
    "            # 삼각형 face의 세 변 (정렬하여 tuple로 사용)\n",
    "            for e in [(face[0], face[1]), (face[1], face[2]), (face[2], face[0])]:\n",
    "                e_sorted = tuple(sorted(e))\n",
    "                if e_sorted not in edge_to_faces:\n",
    "                    edge_to_faces[e_sorted] = []\n",
    "                edge_to_faces[e_sorted].append(f_idx)\n",
    "        edges = list(edge_to_faces.keys())               # 간선 리스트 (고유 간선)\n",
    "        \n",
    "        # 3. 간선 이웃 정보 계산 (각 간선당 최대 4개 이웃 간선)\n",
    "        # 이웃 간선 정의: 하나의 꼭짓점을 공유하는 간선 (1-링 이웃)\n",
    "        vert_to_edges = {v: [] for v in range(len(vertices))}\n",
    "        for e_idx, (v1, v2) in enumerate(edges):\n",
    "            vert_to_edges[v1].append(e_idx)\n",
    "            vert_to_edges[v2].append(e_idx)\n",
    "        neighbors_list = []\n",
    "        for e_idx, (v1, v2) in enumerate(edges):\n",
    "            neighbor_set = set(vert_to_edges[v1] + vert_to_edges[v2])\n",
    "            neighbor_set.discard(e_idx)  # 자기 자신은 제외\n",
    "            neighbors = list(neighbor_set)\n",
    "            # 최대 4개까지 이웃 간선을 선택 (많으면 자르기)\n",
    "            neighbors = neighbors[:4]\n",
    "            # 4개 미만이면 자기 자신으로 패딩하여 크기 고정\n",
    "            while len(neighbors) < 4:\n",
    "                neighbors.append(e_idx)\n",
    "            neighbors_list.append(neighbors)\n",
    "        neighbor_index = torch.tensor(neighbors_list, dtype=torch.long)\n",
    "        \n",
    "        # 4. 간선 특징 계산 (5차원: dihedral, inner1, inner2, ratio1, ratio2)\n",
    "        edge_features = []\n",
    "        for e_idx, (v1, v2) in enumerate(edges):\n",
    "            p1, p2 = vertices[v1], vertices[v2]\n",
    "            # 간선 길이\n",
    "            edge_length = np.linalg.norm(p1 - p2)\n",
    "            # 간선을 공유하는 면 목록\n",
    "            faces_indices = edge_to_faces[(v1, v2)]\n",
    "            # Dihedral angle 계산\n",
    "            if len(faces_indices) == 2:\n",
    "                f1, f2 = faces_indices[0], faces_indices[1]\n",
    "                n1, n2 = face_normals[f1], face_normals[f2]\n",
    "                cos_theta = np.dot(n1, n2) / (np.linalg.norm(n1)*np.linalg.norm(n2) + 1e-8)\n",
    "                cos_theta = np.clip(cos_theta, -1.0, 1.0)\n",
    "                dihedral = np.arccos(cos_theta)\n",
    "            else:\n",
    "                # 인접 면이 하나뿐인 경우 (경계 간선) - dihedral을 0으로 처리\n",
    "                dihedral = 0.0\n",
    "            \n",
    "            # 첫 번째 면의 대향각 및 비율\n",
    "            inner1 = 0.0; ratio1 = 0.0\n",
    "            if len(faces_indices) > 0:\n",
    "                f1 = faces_indices[0]\n",
    "                # 간선의 반대쪽 꼭짓점\n",
    "                face_v = faces[f1]\n",
    "                # 간선을 이루는 두 꼭짓점을 제외한 나머지 한 꼭짓점\n",
    "                opp_v = [v for v in face_v if v not in (v1, v2)][0]\n",
    "                vec1 = vertices[v1] - vertices[opp_v]\n",
    "                vec2 = vertices[v2] - vertices[opp_v]\n",
    "                cos_inner = np.dot(vec1, vec2) / ((np.linalg.norm(vec1)*np.linalg.norm(vec2)) + 1e-8)\n",
    "                cos_inner = np.clip(cos_inner, -1.0, 1.0)\n",
    "                inner1 = np.arccos(cos_inner)\n",
    "                # 높이 계산 (삼각형 면적 이용)\n",
    "                area = np.linalg.norm(np.cross(vec1, vec2)) / 2.0\n",
    "                height = (2.0 * area) / (edge_length + 1e-8)\n",
    "                ratio1 = edge_length / (height + 1e-8)\n",
    "            # 두 번째 면의 대향각 및 비율 (없으면 첫 번째 면 값으로 대체)\n",
    "            inner2 = inner1; ratio2 = ratio1\n",
    "            if len(faces_indices) == 2:\n",
    "                f2 = faces_indices[1]\n",
    "                face_v2 = faces[f2]\n",
    "                opp_v2 = [v for v in face_v2 if v not in (v1, v2)][0]\n",
    "                vec3 = vertices[v1] - vertices[opp_v2]\n",
    "                vec4 = vertices[v2] - vertices[opp_v2]\n",
    "                cos_inner2 = np.dot(vec3, vec4) / ((np.linalg.norm(vec3)*np.linalg.norm(vec4)) + 1e-8)\n",
    "                cos_inner2 = np.clip(cos_inner2, -1.0, 1.0)\n",
    "                inner2 = np.arccos(cos_inner2)\n",
    "                area2 = np.linalg.norm(np.cross(vec3, vec4)) / 2.0\n",
    "                height2 = (2.0 * area2) / (edge_length + 1e-8)\n",
    "                ratio2 = edge_length / (height2 + 1e-8)\n",
    "            # 특징 벡터 구성\n",
    "            edge_features.append([dihedral, inner1, inner2, ratio1, ratio2])\n",
    "        \n",
    "        edge_features = torch.tensor(edge_features, dtype=torch.float32)\n",
    "        \n",
    "        # 5. 분할 레이블 (간선 단위) 생성\n",
    "        if face_labels is not None:\n",
    "            face_labels_arr = face_labels  # numpy array of shape (F,)\n",
    "            edge_labels = []\n",
    "            for e_idx, (v1, v2) in enumerate(edges):\n",
    "                faces_indices = edge_to_faces[(v1, v2)]\n",
    "                # 해당 간선에 인접한 face 중 하나라도 결절(1)인 경우 간선 레이블 1\n",
    "                label = 0\n",
    "                for f_idx in faces_indices:\n",
    "                    if face_labels_arr[f_idx] == 1:\n",
    "                        label = 1\n",
    "                        break\n",
    "                edge_labels.append(label)\n",
    "            edge_labels = torch.tensor(edge_labels, dtype=torch.long)\n",
    "        else:\n",
    "            # face 레이블이 없는 경우 (분할 라벨이 없으면 모두 0으로 처리)\n",
    "            edge_labels = torch.zeros(len(edges), dtype=torch.long)\n",
    "        \n",
    "        # 6. 클래스 레이블 (결절 유무)\n",
    "        class_label = torch.tensor(self.class_labels[idx], dtype=torch.long)\n",
    "        \n",
    "        # 결과 반환: 특징, 이웃정보, 클래스 레이블, 간선 레이블, (필요하면 원본 메쉬 정보도 반환 가능)\n",
    "        sample = {\n",
    "            'edge_features': edge_features,\n",
    "            'neighbor_index': neighbor_index,\n",
    "            'class_label': class_label,\n",
    "            'edge_labels': edge_labels,\n",
    "            'vertices': vertices,   # 시각화를 위해 전달\n",
    "            'faces': faces          # 시각화를 위해 전달\n",
    "        }\n",
    "        \n",
    "        with open(cache_path, 'wb') as f:\n",
    "            pickle.dump(sample, f)\n",
    "\n",
    "        return sample\n",
    "\n",
    "# 데이터셋 및 데이터로더 초기화 예시 (파일 경로는 실제 데이터셋에 맞게 수정해야 함)\n",
    "data_dir = \"C:/Users/konyang/Desktop/MeshCNN_TF/data\"\n",
    "train_dataset = LungNoduleDataset(data_dir, split='train')\n",
    "train_loader = DataLoader(train_dataset, batch_size=1, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d34f4225-68ec-4b26-ad93-6a6a6911b5cf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class MeshConv(nn.Module):\n",
    "    \"\"\"메쉬 간선 합성곱 레이어: 각 간선과 이웃한 4개 간선 (총5개)의 특징을 통합해 출력.\"\"\"\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(MeshConv, self).__init__()\n",
    "        # 5 * in_channels 크기의 입력을 out_channels로 변환\n",
    "        self.linear = nn.Linear(in_channels * 5, out_channels)\n",
    "    \n",
    "    def forward(self, x, neighbor_index):\n",
    "        # x: (E, in_channels) 간선 특징\n",
    "        # neighbor_index: (E, 4) 각 간선의 이웃 간선 인덱스\n",
    "        # 이웃 간선의 특징 수집\n",
    "        # x_neighbors: (E, 4, in_channels)\n",
    "        x_neighbors = x[neighbor_index]  \n",
    "        # x_self: (E, 1, in_channels)\n",
    "        x_self = x.unsqueeze(1)  \n",
    "        # 자신 + 이웃을 concatenation: (E, 5, in_channels)\n",
    "        x_combined = torch.cat([x_self, x_neighbors], dim=1)\n",
    "        # 펼쳐서 Linear 입력으로: (E, 5*in_channels)\n",
    "        x_flat = x_combined.view(x_combined.size(0), -1)\n",
    "        # Linear 변환\n",
    "        out = self.linear(x_flat)\n",
    "        return out  # 출력 크기: (E, out_channels)\n",
    "\n",
    "class MeshPool(nn.Module):\n",
    "    \"\"\"메쉬 풀링 레이어: 간선 수를 감소 (2:1 비율로 클러스터).\"\"\"\n",
    "    def __init__(self):\n",
    "        super(MeshPool, self).__init__()\n",
    "        self.cluster_map = None  # 나중에 unpool에 사용하기 위한 매핑\n",
    "    \n",
    "    def forward(self, x, neighbor_index):\n",
    "        # x: (N, C) 입력 간선 특징, N = 현재 간선 수\n",
    "        N = x.size(0)\n",
    "        # 클러스터 구성: 2개 간선씩 묶음 (홀수개일 경우 마지막은 단독 클러스터)\n",
    "        if N % 2 == 0:\n",
    "            new_N = N // 2\n",
    "        else:\n",
    "            new_N = N // 2 + 1\n",
    "        # 출력 텐서 초기화\n",
    "        device = x.device\n",
    "        C = x.size(1)\n",
    "        x_pooled = torch.zeros((new_N, C), dtype=x.dtype, device=device)\n",
    "        # cluster_map: 길이 N 리스트로, 각 간선이 속한 클러스터 인덱스\n",
    "        cluster_map = [-1] * N\n",
    "        # 2개씩 평균\n",
    "        for i in range(N // 2):\n",
    "            idx1 = 2 * i\n",
    "            idx2 = 2 * i + 1\n",
    "            x_pooled[i] = 0.5 * (x[idx1] + x[idx2])\n",
    "            cluster_map[idx1] = i\n",
    "            cluster_map[idx2] = i\n",
    "        if N % 2 == 1:\n",
    "            # 마지막 간선은 단독 클러스터\n",
    "            x_pooled[new_N - 1] = x[N - 1]\n",
    "            cluster_map[N - 1] = new_N - 1\n",
    "        # cluster_map을 Tensor로 저장\n",
    "        cluster_map = torch.tensor(cluster_map, dtype=torch.long, device=device)\n",
    "        self.cluster_map = cluster_map\n",
    "        \n",
    "        # 새로운 neighbor_index 계산 (클러스터 그래프의 이웃)\n",
    "        neighbors_coarse = []\n",
    "        # 원래 간선의 neighbor_index로부터 클러스터 간 이웃을 유추\n",
    "        for edge_idx in range(N):\n",
    "            cluster_idx = cluster_map[edge_idx].item()\n",
    "            # 원래 간선의 이웃들의 클러스터 인덱스\n",
    "            for nbr_edge in neighbor_index[edge_idx]:\n",
    "                nbr_cluster = cluster_map[nbr_edge].item()\n",
    "                if nbr_cluster != cluster_idx:\n",
    "                    # 리스트 길이를 cluster_idx에 맞춰 확장\n",
    "                    if cluster_idx >= len(neighbors_coarse):\n",
    "                        neighbors_coarse.extend([set() for _ in range(cluster_idx - len(neighbors_coarse) + 1)])\n",
    "                    neighbors_coarse[cluster_idx].add(nbr_cluster)\n",
    "        # 집합을 리스트로 변환하고 4개로 패딩\n",
    "        for i in range(len(neighbors_coarse)):\n",
    "            nbrs = list(neighbors_coarse[i])\n",
    "            nbrs = nbrs[:4]  # 최대 4개까지 사용\n",
    "            while len(nbrs) < 4:\n",
    "                nbrs.append(i)  # 자기 자신으로 패딩\n",
    "            neighbors_coarse[i] = nbrs\n",
    "        # 만약 어떤 클러스터에 대해 neighbor_set이 비어있으면 자기 자신 4개로\n",
    "        if len(neighbors_coarse) < new_N:\n",
    "            # 빈 클러스터 neighbor 세트 초기화\n",
    "            for i in range(len(neighbors_coarse), new_N):\n",
    "                neighbors_coarse.append([i, i, i, i])\n",
    "        neighbor_index_coarse = torch.tensor(neighbors_coarse, dtype=torch.long, device=device)\n",
    "        \n",
    "        return x_pooled, neighbor_index_coarse\n",
    "\n",
    "class MeshUnpool(nn.Module):\n",
    "    \"\"\"메쉬 업풀링 레이어: 풀링된 간선 특징을 원래 개수로 복원.\"\"\"\n",
    "    def forward(self, x_coarse, cluster_map):\n",
    "        # x_coarse: (M, C) 풀링된 간선 특징, cluster_map: (N,) 각 원래 간선 -> 클러스터 인덱스 매핑\n",
    "        device = x_coarse.device\n",
    "        N = cluster_map.shape[0]  # 원래 간선 개수\n",
    "        C = x_coarse.shape[1]\n",
    "        # cluster_map을 이용해 각 원래 간선의 특징 할당\n",
    "        x_reconstructed = torch.zeros((N, C), dtype=x_coarse.dtype, device=device)\n",
    "        # cluster_map의 각 인덱스를 순회하며 할당\n",
    "        for orig_edge_idx, cluster_idx in enumerate(cluster_map):\n",
    "            x_reconstructed[orig_edge_idx] = x_coarse[cluster_idx]\n",
    "        return x_reconstructed\n",
    "\n",
    "# 이제 Encoder, Decoder, Classifier, Segmenter를 정의\n",
    "class MeshEncoder(nn.Module):\n",
    "    def __init__(self, in_channels=5):\n",
    "        super(MeshEncoder, self).__init__()\n",
    "        # 채널 설정: conv1_out=16, conv2_out=32, conv3_out=64 (예시)\n",
    "        self.conv1 = MeshConv(in_channels, 16)\n",
    "        self.pool1 = MeshPool()\n",
    "        self.conv2 = MeshConv(16, 32)\n",
    "        self.pool2 = MeshPool()\n",
    "        self.conv3 = MeshConv(32, 64)\n",
    "    \n",
    "    def forward(self, x, neighbor_index):\n",
    "        # conv1 + ReLU\n",
    "        x1 = F.relu(self.conv1(x, neighbor_index))\n",
    "        # pool1\n",
    "        x_pooled1, neighbor_coarse1 = self.pool1(x1, neighbor_index)\n",
    "        # conv2 + ReLU on pooled1\n",
    "        x2 = F.relu(self.conv2(x_pooled1, neighbor_coarse1))\n",
    "        # pool2\n",
    "        x_pooled2, neighbor_coarse2 = self.pool2(x2, neighbor_coarse1)\n",
    "        # conv3 + ReLU on pooled2 (encoder 최종)\n",
    "        x3 = F.relu(self.conv3(x_pooled2, neighbor_coarse2))\n",
    "        # Encoder 결과와 중간 결과 반환 (스킵 연결 및 Decoder에 필요)\n",
    "        return {\n",
    "            'x1': x1,                       # original level features (E edges, 16ch)\n",
    "            'neighbor0': neighbor_index, \n",
    "            'x2': x2,                       # half level features (E/2 edges, 32ch)\n",
    "            'neighbor1': neighbor_coarse1,\n",
    "            'x3': x3,                       # quarter level features (E/4 edges, 64ch)\n",
    "            'neighbor2': neighbor_coarse2,\n",
    "            'pool1': self.pool1,\n",
    "            'pool2': self.pool2\n",
    "        }\n",
    "\n",
    "class MeshDecoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MeshDecoder, self).__init__()\n",
    "        # Decoder conv layers (업샘플 후 특징 합성)\n",
    "        # conv2_up: 입력 채널 = 32(skip) + 64(decoder up) = 96, 출력 32\n",
    "        self.conv2_up = MeshConv(32 + 64, 32)\n",
    "        # conv1_up: 입력 채널 = 16(skip) + 32(decoder up) = 48, 출력 16\n",
    "        self.conv1_up = MeshConv(16 + 32, 16)\n",
    "    \n",
    "    def forward(self, enc_out):\n",
    "        # enc_out: Encoder의 출력 딕셔너리\n",
    "        x2 = enc_out['x2']\n",
    "        x3 = enc_out['x3']\n",
    "        neighbor1 = enc_out['neighbor1']\n",
    "        neighbor0 = enc_out['neighbor0']\n",
    "        pool1_layer = enc_out['pool1']\n",
    "        pool2_layer = enc_out['pool2']\n",
    "        \n",
    "        # 1. 업풀링 두 번째 풀 (quarter -> half)\n",
    "        x2_up = MeshUnpool().forward(x3, pool2_layer.cluster_map)  # quarter->half 복원 (32ch)\n",
    "        # 2. 스킵 연결 결합 (half 해상도): Encoder의 x2와 concat\n",
    "        x2_cat = torch.cat([x2, x2_up], dim=1)  # shape: (E/2, 96)\n",
    "        # 3. conv2_up + ReLU (half 해상도 특징 복원)\n",
    "        x2_up_refined = F.relu(self.conv2_up(x2_cat, neighbor1))\n",
    "        # 4. 업풀링 첫 번째 풀 (half -> original)\n",
    "        x1_up = MeshUnpool().forward(x2_up_refined, pool1_layer.cluster_map)  # half->original 복원 (16ch+)\n",
    "        # 5. 스킵 연결 결합 (original 해상도): Encoder의 x1과 concat\n",
    "        x1 = enc_out['x1']\n",
    "        x1_cat = torch.cat([x1, x1_up], dim=1)  # shape: (E, 48)\n",
    "        # 6. conv1_up + ReLU (original 해상도 특징 복원)\n",
    "        x1_up_refined = F.relu(self.conv1_up(x1_cat, neighbor0))\n",
    "        return x1_up_refined  # (E, 16) 원래 간선 수의 복원된 특징\n",
    "\n",
    "class ClassificationHead(nn.Module):\n",
    "    def __init__(self, in_channels, hidden_dim=100, num_classes=2):\n",
    "        super(ClassificationHead, self).__init__()\n",
    "        # 단순한 MLP 분류기: [in_channels] -> [hidden_dim] -> [num_classes]\n",
    "        self.fc1 = nn.Linear(in_channels, hidden_dim)\n",
    "        self.fc2 = nn.Linear(hidden_dim, num_classes)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # x: (in_channels) or (1, in_channels) 전역 특징 벡터\n",
    "        x = F.relu(self.fc1(x))\n",
    "        out = self.fc2(x)\n",
    "        return out  # raw logits (num_classes)\n",
    "    \n",
    "class SegmentationHead(nn.Module):\n",
    "    def __init__(self, in_channels, num_classes=2):\n",
    "        super(SegmentationHead, self).__init__()\n",
    "        self.linear = nn.Linear(in_channels, num_classes)\n",
    "    def forward(self, x):\n",
    "        # x: (E, in_channels) 모든 원래 간선에 대한 복원된 특징\n",
    "        out = self.linear(x)  # (E, num_classes)\n",
    "        return out\n",
    "\n",
    "# 전체 모델 통합\n",
    "class MedMeshNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MedMeshNet, self).__init__()\n",
    "        self.encoder = MeshEncoder(in_channels=5)\n",
    "        self.decoder = MeshDecoder()\n",
    "        # classification은 encoder 최종 출력 채널 (예: 64)을 받아 이진 분류\n",
    "        self.classifier = ClassificationHead(in_channels=64, hidden_dim=100, num_classes=2)\n",
    "        # segmentation은 decoder 최종 출력 채널 (예: 16)을 받아 2-class 출력\n",
    "        self.segmenter = SegmentationHead(in_channels=16, num_classes=2)\n",
    "    \n",
    "    def forward(self, edge_features, neighbor_index):\n",
    "        # 1. Encoder: 특징 추출 및 다운샘플\n",
    "        enc_out = self.encoder(edge_features, neighbor_index)\n",
    "        # 2. Classification: Encoder 최종 특징들을 전역 요약하여 클래스 예측\n",
    "        x_global = torch.max(enc_out['x3'], dim=0)[0]  # 전역 max 풀 (64차원 벡터)\n",
    "        class_logits = self.classifier(x_global.unsqueeze(0))  # (1,2) 출력\n",
    "        # 3. Decoder: 업샘플로 원래 해상도 특징 복원\n",
    "        dec_out = self.decoder(enc_out)  # (E, 16)\n",
    "        seg_logits = self.segmenter(dec_out)  # (E, 2)\n",
    "        return class_logits, seg_logits\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "070f29ce-e5f9-45d0-a1e7-72073258fd30",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "features: torch.Size([1, 744127, 5])\n",
      "neighbor_index: torch.Size([1, 744127, 4])\n",
      "neighbor_index min: 0\n",
      "neighbor_index max: 744126\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA out of memory. Tried to allocate 41255.73 GiB (GPU 0; 8.00 GiB total capacity; 42.73 MiB already allocated; 5.93 GiB free; 62.00 MiB reserved in total by PyTorch)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 38\u001b[0m\n\u001b[0;32m     35\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mneighbor_index max:\u001b[39m\u001b[38;5;124m\"\u001b[39m, neighbor_index\u001b[38;5;241m.\u001b[39mmax()\u001b[38;5;241m.\u001b[39mitem())\n\u001b[0;32m     37\u001b[0m \u001b[38;5;66;03m# 순전파\u001b[39;00m\n\u001b[1;32m---> 38\u001b[0m class_logits, seg_logits \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfeatures\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mneighbor_index\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# class_logits: (B, C), seg_logits: (E, C)\u001b[39;00m\n\u001b[0;32m     40\u001b[0m \u001b[38;5;66;03m# 손실 계산\u001b[39;00m\n\u001b[0;32m     41\u001b[0m loss_class \u001b[38;5;241m=\u001b[39m criterion_class(class_logits, class_label)\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\envs\\project2025\\lib\\site-packages\\torch\\nn\\modules\\module.py:727\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    725\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_slow_forward(\u001b[38;5;241m*\u001b[39m\u001b[38;5;28minput\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    726\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 727\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mforward(\u001b[38;5;241m*\u001b[39m\u001b[38;5;28minput\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    728\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m hook \u001b[38;5;129;01min\u001b[39;00m itertools\u001b[38;5;241m.\u001b[39mchain(\n\u001b[0;32m    729\u001b[0m         _global_forward_hooks\u001b[38;5;241m.\u001b[39mvalues(),\n\u001b[0;32m    730\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks\u001b[38;5;241m.\u001b[39mvalues()):\n\u001b[0;32m    731\u001b[0m     hook_result \u001b[38;5;241m=\u001b[39m hook(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m, result)\n",
      "Cell \u001b[1;32mIn[3], line 204\u001b[0m, in \u001b[0;36mMedMeshNet.forward\u001b[1;34m(self, edge_features, neighbor_index)\u001b[0m\n\u001b[0;32m    202\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, edge_features, neighbor_index):\n\u001b[0;32m    203\u001b[0m     \u001b[38;5;66;03m# 1. Encoder: 특징 추출 및 다운샘플\u001b[39;00m\n\u001b[1;32m--> 204\u001b[0m     enc_out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoder\u001b[49m\u001b[43m(\u001b[49m\u001b[43medge_features\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mneighbor_index\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    205\u001b[0m     \u001b[38;5;66;03m# 2. Classification: Encoder 최종 특징들을 전역 요약하여 클래스 예측\u001b[39;00m\n\u001b[0;32m    206\u001b[0m     x_global \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mmax(enc_out[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mx3\u001b[39m\u001b[38;5;124m'\u001b[39m], dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)[\u001b[38;5;241m0\u001b[39m]  \u001b[38;5;66;03m# 전역 max 풀 (64차원 벡터)\u001b[39;00m\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\envs\\project2025\\lib\\site-packages\\torch\\nn\\modules\\module.py:727\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    725\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_slow_forward(\u001b[38;5;241m*\u001b[39m\u001b[38;5;28minput\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    726\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 727\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mforward(\u001b[38;5;241m*\u001b[39m\u001b[38;5;28minput\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    728\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m hook \u001b[38;5;129;01min\u001b[39;00m itertools\u001b[38;5;241m.\u001b[39mchain(\n\u001b[0;32m    729\u001b[0m         _global_forward_hooks\u001b[38;5;241m.\u001b[39mvalues(),\n\u001b[0;32m    730\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks\u001b[38;5;241m.\u001b[39mvalues()):\n\u001b[0;32m    731\u001b[0m     hook_result \u001b[38;5;241m=\u001b[39m hook(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m, result)\n",
      "Cell \u001b[1;32mIn[3], line 115\u001b[0m, in \u001b[0;36mMeshEncoder.forward\u001b[1;34m(self, x, neighbor_index)\u001b[0m\n\u001b[0;32m    113\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x, neighbor_index):\n\u001b[0;32m    114\u001b[0m     \u001b[38;5;66;03m# conv1 + ReLU\u001b[39;00m\n\u001b[1;32m--> 115\u001b[0m     x1 \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mrelu(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv1\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mneighbor_index\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m    116\u001b[0m     \u001b[38;5;66;03m# pool1\u001b[39;00m\n\u001b[0;32m    117\u001b[0m     x_pooled1, neighbor_coarse1 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpool1(x1, neighbor_index)\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\envs\\project2025\\lib\\site-packages\\torch\\nn\\modules\\module.py:727\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    725\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_slow_forward(\u001b[38;5;241m*\u001b[39m\u001b[38;5;28minput\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    726\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 727\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mforward(\u001b[38;5;241m*\u001b[39m\u001b[38;5;28minput\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    728\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m hook \u001b[38;5;129;01min\u001b[39;00m itertools\u001b[38;5;241m.\u001b[39mchain(\n\u001b[0;32m    729\u001b[0m         _global_forward_hooks\u001b[38;5;241m.\u001b[39mvalues(),\n\u001b[0;32m    730\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks\u001b[38;5;241m.\u001b[39mvalues()):\n\u001b[0;32m    731\u001b[0m     hook_result \u001b[38;5;241m=\u001b[39m hook(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m, result)\n",
      "Cell \u001b[1;32mIn[3], line 13\u001b[0m, in \u001b[0;36mMeshConv.forward\u001b[1;34m(self, x, neighbor_index)\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x, neighbor_index):\n\u001b[0;32m      9\u001b[0m     \u001b[38;5;66;03m# x: (E, in_channels) 간선 특징\u001b[39;00m\n\u001b[0;32m     10\u001b[0m     \u001b[38;5;66;03m# neighbor_index: (E, 4) 각 간선의 이웃 간선 인덱스\u001b[39;00m\n\u001b[0;32m     11\u001b[0m     \u001b[38;5;66;03m# 이웃 간선의 특징 수집\u001b[39;00m\n\u001b[0;32m     12\u001b[0m     \u001b[38;5;66;03m# x_neighbors: (E, 4, in_channels)\u001b[39;00m\n\u001b[1;32m---> 13\u001b[0m     x_neighbors \u001b[38;5;241m=\u001b[39m \u001b[43mx\u001b[49m\u001b[43m[\u001b[49m\u001b[43mneighbor_index\u001b[49m\u001b[43m]\u001b[49m  \n\u001b[0;32m     14\u001b[0m     \u001b[38;5;66;03m# x_self: (E, 1, in_channels)\u001b[39;00m\n\u001b[0;32m     15\u001b[0m     x_self \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m1\u001b[39m)  \n",
      "\u001b[1;31mRuntimeError\u001b[0m: CUDA out of memory. Tried to allocate 41255.73 GiB (GPU 0; 8.00 GiB total capacity; 42.73 MiB already allocated; 5.93 GiB free; 62.00 MiB reserved in total by PyTorch)"
     ]
    }
   ],
   "source": [
    "# 모델 초기화\n",
    "model = MedMeshNet().to(device)\n",
    "\n",
    "# 손실 함수 정의\n",
    "criterion_class = nn.CrossEntropyLoss()  # 분류 손실\n",
    "criterion_seg = nn.CrossEntropyLoss()    # 분할 손실 (다중 클래스용)\n",
    "\n",
    "# 옵티마이저 & 스케줄러 설정\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.5)\n",
    "\n",
    "# 검증용 val_loader 존재 확인\n",
    "try:\n",
    "    val_loader\n",
    "except NameError:\n",
    "    val_loader = None\n",
    "\n",
    "# 학습 루프\n",
    "num_epochs = 10\n",
    "for epoch in range(1, num_epochs + 1):\n",
    "    model.train()\n",
    "    total_loss = 0.0\n",
    "\n",
    "    for batch in train_loader:\n",
    "        features = batch['edge_features'].to(device)       # (E, 5)\n",
    "        neighbor_index = batch['neighbor_index'].to(device)  # (E, 4)\n",
    "        class_label = batch['class_label'].to(device)      # (B,)\n",
    "        seg_label = batch['edge_labels'].to(device)        # (E,)\n",
    "\n",
    "        # 디버깅 로그\n",
    "        if epoch == 1:\n",
    "            print(\"features:\", features.shape)\n",
    "            print(\"neighbor_index:\", neighbor_index.shape)\n",
    "            print(\"neighbor_index min:\", neighbor_index.min().item())\n",
    "            print(\"neighbor_index max:\", neighbor_index.max().item())\n",
    "\n",
    "        # 순전파\n",
    "        class_logits, seg_logits = model(features, neighbor_index)  # class_logits: (B, C), seg_logits: (E, C)\n",
    "\n",
    "        # 손실 계산\n",
    "        loss_class = criterion_class(class_logits, class_label)\n",
    "        loss_seg = criterion_seg(seg_logits, seg_label)\n",
    "        loss = loss_class + loss_seg\n",
    "\n",
    "        # 역전파 및 최적화\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    avg_loss = total_loss / len(train_loader)\n",
    "    print(f\"[Epoch {epoch}] 평균 훈련 손실: {avg_loss:.4f}\")\n",
    "\n",
    "    # 스케줄러 업데이트\n",
    "    scheduler.step()\n",
    "\n",
    "    # ---------------------------\n",
    "    # 검증 단계\n",
    "    # ---------------------------\n",
    "    if val_loader is not None:\n",
    "        model.eval()\n",
    "        correct = 0\n",
    "        total_samples = 0\n",
    "        inter = 0\n",
    "        union = 0\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for batch in val_loader:\n",
    "                features = batch['edge_features'].to(device)\n",
    "                neighbor_index = batch['neighbor_index'].to(device)\n",
    "                class_label = batch['class_label'].to(device)\n",
    "                seg_label = batch['edge_labels'].to(device)\n",
    "\n",
    "                # 순전파\n",
    "                class_logits, seg_logits = model(features, neighbor_index)\n",
    "\n",
    "                # 분류 정확도\n",
    "                pred_class = torch.argmax(class_logits, dim=1)\n",
    "                correct += (pred_class == class_label).sum().item()\n",
    "                total_samples += class_label.size(0)\n",
    "\n",
    "                # 분할 IoU (다중 클래스 대응)\n",
    "                pred_seg = torch.argmax(seg_logits, dim=1)\n",
    "                num_classes = seg_logits.shape[1]\n",
    "\n",
    "                for cls in range(num_classes):\n",
    "                    inter += ((pred_seg == cls) & (seg_label == cls)).sum().item()\n",
    "                    union += ((pred_seg == cls) | (seg_label == cls)).sum().item()\n",
    "\n",
    "        val_acc = correct / total_samples if total_samples > 0 else 0\n",
    "        val_iou = inter / (union + 1e-8) if union > 0 else 0\n",
    "        print(f\"  - 검증 정확도: {val_acc * 100:.2f}%, 검증 IoU: {val_iou:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f193d949-6b61-454f-8bb8-eaf9e7214ca8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_classification_accuracy(model, data_loader):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for batch in data_loader:\n",
    "            features = batch['edge_features'].to(device)\n",
    "            neighbor_index = batch['neighbor_index'].to(device)\n",
    "            labels = batch['class_label'].to(device)\n",
    "            class_logits, _ = model(features, neighbor_index)\n",
    "            pred = torch.argmax(class_logits, dim=1)  # 예측 클래스\n",
    "            if pred.item() == labels.item():\n",
    "                correct += 1\n",
    "            total += 1\n",
    "    acc = correct / total if total > 0 else 0\n",
    "    return acc\n",
    "\n",
    "def compute_segmentation_iou(model, data_loader):\n",
    "    model.eval()\n",
    "    inter = 0\n",
    "    union = 0\n",
    "    with torch.no_grad():\n",
    "        for batch in data_loader:\n",
    "            features = batch['edge_features'].to(device)\n",
    "            neighbor_index = batch['neighbor_index'].to(device)\n",
    "            true_seg = batch['edge_labels'].to(device)\n",
    "            _, seg_logits = model(features, neighbor_index)\n",
    "            pred_seg = torch.argmax(seg_logits, dim=1)\n",
    "            # 결절 클래스(1)에 대한 IoU 계산\n",
    "            inter += torch.logical_and(pred_seg == 1, true_seg == 1).sum().item()\n",
    "            union += torch.logical_or(pred_seg == 1, true_seg == 1).sum().item()\n",
    "    iou = inter / (union + 1e-8) if union > 0 else 0\n",
    "    return iou\n",
    "\n",
    "# 예시: 학습 완료 후 테스트 세트에 대한 성능 측정\n",
    "\n",
    "test_acc = compute_classification_accuracy(model, test_loader)\n",
    "test_iou = compute_segmentation_iou(model, test_loader)\n",
    "print(f\"테스트 정확도: {test_acc:.4f}, 테스트 IoU: {test_iou:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "530f305c-f902-4695-ace0-43183cb78971",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 예측 및 시각화 예시 (단일 샘플)\n",
    "model.eval()\n",
    "sample = val_dataset[0]  # 검증 세트 첫 번째 샘플 (예시)\n",
    "features = sample['edge_features'].to(device)\n",
    "neighbor_index = sample['neighbor_index'].to(device)\n",
    "vertices = sample['vertices']  # numpy array\n",
    "faces = sample['faces']        # numpy array\n",
    "\n",
    "# 모델 예측\n",
    "class_logits, seg_logits = model(features, neighbor_index)\n",
    "pred_class = torch.argmax(class_logits, dim=1).item()  # 0 또는 1\n",
    "pred_seg = torch.argmax(seg_logits, dim=1).cpu().numpy()  # 각 간선의 예측 클래스 (numpy로 변환)\n",
    "\n",
    "# 결과 출력 - 분류\n",
    "if pred_class == 1:\n",
    "    print(\"모델 예측: 이 메쉬에서 폐 결절이 검출되었습니다.\")\n",
    "else:\n",
    "    print(\"모델 예측: 이 메쉬에는 결절이 없습니다.\")\n",
    "\n",
    "# 시각화를 위해 간선->면 매핑 다시 계산 (sample 생성 시 활용 가능)\n",
    "edge_to_faces = {}\n",
    "for f_idx, face in enumerate(faces):\n",
    "    for e in [(face[0], face[1]), (face[1], face[2]), (face[2], face[0])]:\n",
    "        e_sorted = tuple(sorted(e))\n",
    "        if e_sorted not in edge_to_faces:\n",
    "            edge_to_faces[e_sorted] = []\n",
    "        edge_to_faces[e_sorted].append(f_idx)\n",
    "edges = list(edge_to_faces.keys())\n",
    "\n",
    "# 예측된 결절 간선들에 인접한 face 수집\n",
    "pred_nodule_faces = set()\n",
    "for e_idx, edge in enumerate(edges):\n",
    "    if pred_seg[e_idx] == 1:  # 간선이 결절로 예측된 경우\n",
    "        for f_idx in edge_to_faces[edge]:\n",
    "            pred_nodule_faces.add(f_idx)\n",
    "\n",
    "pred_nodule_faces = list(pred_nodule_faces)\n",
    "print(f\"예측된 결절 영역에 포함된 면 개수: {len(pred_nodule_faces)}개\")\n",
    "\n",
    "# 메쉬 객체 생성 (trimesh) 및 face 색상 지정\n",
    "mesh = trimesh.Trimesh(vertices=vertices, faces=faces)\n",
    "# 기본 face 색을 회색으로\n",
    "face_colors = np.tile([200, 200, 200, 255], (len(faces), 1))  # RGBA\n",
    "# 결절 예측 faces를 빨간색으로 칠함\n",
    "for f_idx in pred_nodule_faces:\n",
    "    face_colors[f_idx] = [255, 0, 0, 255]  # 빨간색 RGBA\n",
    "mesh.visual.face_colors = face_colors\n",
    "\n",
    "# matplotlib 3D 출력\n",
    "font_location = 'C:/Windows/Fonts/HANDotum.ttf'\n",
    "font_name = fm.FontProperties(fname=font_location).get_name()\n",
    "plt.rc('font', family=font_name)\n",
    "plt.rcParams['axes.unicode_minus'] = False\n",
    "\n",
    "fig = plt.figure(figsize=(6,6))\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "# 각 face를 폴리곤으로 plot\n",
    "for f_idx, face in enumerate(mesh.faces):\n",
    "    tri_coords = mesh.vertices[face]  # (3,3) 좌표\n",
    "    # 삼각형을 폴리곤으로 추가\n",
    "    tri = plt.Polygon(tri_coords[:, :2], closed=True, facecolor=face_colors[f_idx][:3]/255, edgecolor=None)\n",
    "    # Note: 위에서는 2D 평면에 투영해서 그리므로 z좌표 무시 (간단화를 위해)\n",
    "ax.add_collection3d(plt.PolyCollection([mesh.vertices[face]], facecolors=face_colors[f_idx][:3]/255, linewidths=0.1, edgecolors='k', alpha=0.9))\n",
    "# 위의 방식은 단순화된 예이며, 보다 나은 3D 시각화를 위해서는 pyvista 등 사용 가능\n",
    "plt.title(\"예측된 결절 부위 시각화\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1b85ce8-df33-4b59-bebb-25f16c2d043f",
   "metadata": {},
   "source": [
    "하이퍼파라미터 조정, 데이터 증강, 평가 지표 추가 및 최적화 등 추가 작업 필요"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "project2025",
   "language": "python",
   "name": "project2025"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
