{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d1035b36-69ce-45f6-a288-4936a930c542",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "# ê¸°ë³¸ íŒ¨í‚¤ì§€ ì„í¬íŠ¸\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import os, trimesh, pickle\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.font_manager as fm\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.cuda.amp import autocast, GradScaler\n",
    "\n",
    "# ë””ë°”ì´ìŠ¤ ì„¤ì • (GPU ì‚¬ìš© ê°€ëŠ¥ ì‹œ GPUë¡œ ì„¤ì •)\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(\"Using device:\", device)\n",
    "torch.backends.cudnn.benchmark = True\n",
    "torch.backends.cudnn.enabled = True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7bb13ab-2a4f-4991-a241-d29213248174",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def generate_npz_cache(mesh_dir, cache_dir):\n",
    "    os.makedirs(cache_dir, exist_ok=True)\n",
    "\n",
    "    mesh_files = [f for f in os.listdir(mesh_dir)\n",
    "                  if f.endswith('.obj') or f.endswith('.stl') or f.endswith('.ply')]\n",
    "\n",
    "    for fname in mesh_files:\n",
    "        mesh_path = os.path.join(mesh_dir, fname)\n",
    "        cache_path = os.path.join(cache_dir, fname.replace('.obj', '.npz').replace('.stl', '.npz').replace('.ply', '.npz'))\n",
    "\n",
    "        # ì´ë¯¸ ìºì‹œëœ ê²½ìš° ìƒëµ\n",
    "        if os.path.exists(cache_path):\n",
    "            print(f\"âœ… ì¡´ì¬í•¨: {cache_path} â†’ ê±´ë„ˆëœ€\")\n",
    "            continue\n",
    "\n",
    "        try:\n",
    "            mesh = trimesh.load(mesh_path, process=False)\n",
    "            vertices = np.array(mesh.vertices)\n",
    "            faces = np.array(mesh.faces)\n",
    "            face_normals = np.array(mesh.face_normals)\n",
    "\n",
    "            np.savez(cache_path, vertices=vertices, faces=faces, face_normals=face_normals)\n",
    "            print(f\"ğŸ’¾ ì €ì¥ë¨: {cache_path}\")\n",
    "        except Exception as e:\n",
    "            print(f\"âŒ ì‹¤íŒ¨: {fname} â†’ {e}\")\n",
    "\n",
    "# ğŸ”§ ê²½ë¡œ ì§€ì •\n",
    "source_mesh_dir = r\"C:\\Users\\konyang\\Desktop\\MeshCNN_TF\\data\\dataset\\simplified_mesh\\test\"\n",
    "target_cache_dir = r\"C:\\Users\\konyang\\Desktop\\MeshCNN_TF\\data\\dataset\\cached_mesh\\test\"\n",
    "\n",
    "# ì‹¤í–‰\n",
    "generate_npz_cache(source_mesh_dir, target_cache_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "70d996f3-807e-4bcf-9a03-d51f9b850be1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class LungNoduleDataset(Dataset):\n",
    "    def __init__(self, data_dir, split='train', cache_dir=None):\n",
    "        self.mesh_files = []\n",
    "        self.face_labels = []\n",
    "        self.class_labels = []\n",
    "        self.cache_dir = cache_dir\n",
    "\n",
    "        mesh_dir = os.path.join(data_dir, split)\n",
    "        label_dir = os.path.join(data_dir.replace(\"simplified_mesh\", \"simplified_label\"), split)\n",
    "\n",
    "        if self.cache_dir:\n",
    "            os.makedirs(os.path.join(self.cache_dir, split), exist_ok=True)\n",
    "\n",
    "        for fname in os.listdir(mesh_dir):\n",
    "            if fname.endswith('.obj') or fname.endswith('.stl') or fname.endswith('.ply'):\n",
    "                mesh_path = os.path.join(mesh_dir, fname)\n",
    "                label_path = os.path.join(label_dir, fname.split('.')[0] + \"_label.npy\")\n",
    "\n",
    "                if os.path.exists(label_path):\n",
    "                    face_label = np.load(label_path)\n",
    "                    class_label = 1 if face_label.sum() > 0 else 0\n",
    "                else:\n",
    "                    face_label = None\n",
    "                    class_label = 0\n",
    "\n",
    "                self.mesh_files.append((mesh_path, label_path))\n",
    "                self.class_labels.append(class_label)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.mesh_files)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        mesh_path, label_path = self.mesh_files[idx]\n",
    "        fname = os.path.splitext(os.path.basename(mesh_path))[0]\n",
    "        \n",
    "        try:\n",
    "            # -----------------------------------------\n",
    "            # âœ… 1. ìºì‹œ ë¶ˆëŸ¬ì˜¤ê¸° or ìƒì„±\n",
    "            # -----------------------------------------\n",
    "            if self.cache_dir:\n",
    "                cached_path = os.path.join(self.cache_dir, fname + \".npz\")\n",
    "                if os.path.exists(cached_path):\n",
    "                    data = np.load(cached_path)\n",
    "                    vertices = data['vertices']\n",
    "                    faces = data['faces']\n",
    "                    face_normals = data['face_normals']\n",
    "                else:\n",
    "                    mesh = trimesh.load(mesh_path)\n",
    "                    vertices = np.array(mesh.vertices)\n",
    "                    faces = np.array(mesh.faces)\n",
    "                    face_normals = np.array(mesh.face_normals)\n",
    "                    np.savez(cached_path, vertices=vertices, faces=faces, face_normals=face_normals)\n",
    "            else:\n",
    "                mesh = trimesh.load(mesh_path)\n",
    "                vertices = np.array(mesh.vertices)\n",
    "                faces = np.array(mesh.faces)\n",
    "                face_normals = np.array(mesh.face_normals)\n",
    "\n",
    "            # -----------------------------------------\n",
    "            # âœ… 2. ë ˆì´ë¸” ë¶ˆëŸ¬ì˜¤ê¸°\n",
    "            # -----------------------------------------\n",
    "            if os.path.exists(label_path):\n",
    "                face_label = np.load(label_path)\n",
    "            else:\n",
    "                face_label = None\n",
    "\n",
    "             # 2. ê°„ì„  ë° ê°„ì„ ->ë©´ ë§¤í•‘ ìƒì„±\n",
    "            edge_to_faces = {}\n",
    "            for f_idx, face in enumerate(faces):\n",
    "                # ì‚¼ê°í˜• faceì˜ ì„¸ ë³€ (ì •ë ¬í•˜ì—¬ tupleë¡œ ì‚¬ìš©)\n",
    "                for e in [(face[0], face[1]), (face[1], face[2]), (face[2], face[0])]:\n",
    "                    e_sorted = tuple(sorted(e))\n",
    "                    if e_sorted not in edge_to_faces:\n",
    "                        edge_to_faces[e_sorted] = []\n",
    "                    edge_to_faces[e_sorted].append(f_idx)\n",
    "            edges = list(edge_to_faces.keys())               # ê°„ì„  ë¦¬ìŠ¤íŠ¸ (ê³ ìœ  ê°„ì„ )\n",
    "\n",
    "            # 3. ê°„ì„  ì´ì›ƒ ì •ë³´ ê³„ì‚° (ê° ê°„ì„ ë‹¹ ìµœëŒ€ 4ê°œ ì´ì›ƒ ê°„ì„ )\n",
    "            # ì´ì›ƒ ê°„ì„  ì •ì˜: í•˜ë‚˜ì˜ ê¼­ì§“ì ì„ ê³µìœ í•˜ëŠ” ê°„ì„  (1-ë§ ì´ì›ƒ)\n",
    "            vert_to_edges = {v: [] for v in range(len(vertices))}\n",
    "            for e_idx, (v1, v2) in enumerate(edges):\n",
    "                vert_to_edges[v1].append(e_idx)\n",
    "                vert_to_edges[v2].append(e_idx)\n",
    "            neighbors_list = []\n",
    "            for e_idx, (v1, v2) in enumerate(edges):\n",
    "                neighbor_set = set(vert_to_edges[v1] + vert_to_edges[v2])\n",
    "                neighbor_set.discard(e_idx)  # ìê¸° ìì‹ ì€ ì œì™¸\n",
    "                neighbors = list(neighbor_set)\n",
    "                # ìµœëŒ€ 4ê°œê¹Œì§€ ì´ì›ƒ ê°„ì„ ì„ ì„ íƒ (ë§ìœ¼ë©´ ìë¥´ê¸°)\n",
    "                neighbors = neighbors[:4]\n",
    "                # 4ê°œ ë¯¸ë§Œì´ë©´ ìê¸° ìì‹ ìœ¼ë¡œ íŒ¨ë”©í•˜ì—¬ í¬ê¸° ê³ ì •\n",
    "                while len(neighbors) < 4:\n",
    "                    neighbors.append(e_idx)\n",
    "                neighbors_list.append(neighbors)\n",
    "            neighbor_index = torch.tensor(neighbors_list, dtype=torch.long)\n",
    "\n",
    "            # 4. ê°„ì„  íŠ¹ì§• ê³„ì‚° (5ì°¨ì›: dihedral, inner1, inner2, ratio1, ratio2)\n",
    "            edge_features = []\n",
    "            for e_idx, (v1, v2) in enumerate(edges):\n",
    "                p1, p2 = vertices[v1], vertices[v2]\n",
    "                # ê°„ì„  ê¸¸ì´\n",
    "                edge_length = np.linalg.norm(p1 - p2)\n",
    "                # ê°„ì„ ì„ ê³µìœ í•˜ëŠ” ë©´ ëª©ë¡\n",
    "                faces_indices = edge_to_faces[(v1, v2)]\n",
    "                # Dihedral angle ê³„ì‚°\n",
    "                if len(faces_indices) == 2:\n",
    "                    f1, f2 = faces_indices[0], faces_indices[1]\n",
    "                    n1, n2 = face_normals[f1], face_normals[f2]\n",
    "                    cos_theta = np.dot(n1, n2) / (np.linalg.norm(n1)*np.linalg.norm(n2) + 1e-8)\n",
    "                    cos_theta = np.clip(cos_theta, -1.0, 1.0)\n",
    "                    dihedral = np.arccos(cos_theta)\n",
    "                else:\n",
    "                    # ì¸ì ‘ ë©´ì´ í•˜ë‚˜ë¿ì¸ ê²½ìš° (ê²½ê³„ ê°„ì„ ) - dihedralì„ 0ìœ¼ë¡œ ì²˜ë¦¬\n",
    "                    dihedral = 0.0\n",
    "\n",
    "                # ì²« ë²ˆì§¸ ë©´ì˜ ëŒ€í–¥ê° ë° ë¹„ìœ¨\n",
    "                inner1 = 0.0; ratio1 = 0.0\n",
    "                if len(faces_indices) > 0:\n",
    "                    f1 = faces_indices[0]\n",
    "                    # ê°„ì„ ì˜ ë°˜ëŒ€ìª½ ê¼­ì§“ì \n",
    "                    face_v = faces[f1]\n",
    "                    # ê°„ì„ ì„ ì´ë£¨ëŠ” ë‘ ê¼­ì§“ì ì„ ì œì™¸í•œ ë‚˜ë¨¸ì§€ í•œ ê¼­ì§“ì \n",
    "                    opp_v = [v for v in face_v if v not in (v1, v2)][0]\n",
    "                    vec1 = vertices[v1] - vertices[opp_v]\n",
    "                    vec2 = vertices[v2] - vertices[opp_v]\n",
    "                    cos_inner = np.dot(vec1, vec2) / ((np.linalg.norm(vec1)*np.linalg.norm(vec2)) + 1e-8)\n",
    "                    cos_inner = np.clip(cos_inner, -1.0, 1.0)\n",
    "                    inner1 = np.arccos(cos_inner)\n",
    "                    # ë†’ì´ ê³„ì‚° (ì‚¼ê°í˜• ë©´ì  ì´ìš©)\n",
    "                    area = np.linalg.norm(np.cross(vec1, vec2)) / 2.0\n",
    "                    height = (2.0 * area) / (edge_length + 1e-8)\n",
    "                    ratio1 = edge_length / (height + 1e-8)\n",
    "                # ë‘ ë²ˆì§¸ ë©´ì˜ ëŒ€í–¥ê° ë° ë¹„ìœ¨ (ì—†ìœ¼ë©´ ì²« ë²ˆì§¸ ë©´ ê°’ìœ¼ë¡œ ëŒ€ì²´)\n",
    "                inner2 = inner1; ratio2 = ratio1\n",
    "                if len(faces_indices) == 2:\n",
    "                    f2 = faces_indices[1]\n",
    "                    face_v2 = faces[f2]\n",
    "                    opp_v2 = [v for v in face_v2 if v not in (v1, v2)][0]\n",
    "                    vec3 = vertices[v1] - vertices[opp_v2]\n",
    "                    vec4 = vertices[v2] - vertices[opp_v2]\n",
    "                    cos_inner2 = np.dot(vec3, vec4) / ((np.linalg.norm(vec3)*np.linalg.norm(vec4)) + 1e-8)\n",
    "                    cos_inner2 = np.clip(cos_inner2, -1.0, 1.0)\n",
    "                    inner2 = np.arccos(cos_inner2)\n",
    "                    area2 = np.linalg.norm(np.cross(vec3, vec4)) / 2.0\n",
    "                    height2 = (2.0 * area2) / (edge_length + 1e-8)\n",
    "                    ratio2 = edge_length / (height2 + 1e-8)\n",
    "                # íŠ¹ì§• ë²¡í„° êµ¬ì„±\n",
    "                edge_features.append([dihedral, inner1, inner2, ratio1, ratio2])\n",
    "\n",
    "            edge_features = torch.tensor(edge_features, dtype=torch.float32)\n",
    "\n",
    "            # 5. ë¶„í•  ë ˆì´ë¸” (ê°„ì„  ë‹¨ìœ„) ìƒì„±\n",
    "            if face_label is not None:\n",
    "                face_labels_arr = face_label # numpy array of shape (F,)\n",
    "                edge_labels = []\n",
    "                for e_idx, (v1, v2) in enumerate(edges):\n",
    "                    faces_indices = edge_to_faces[(v1, v2)]\n",
    "                    # í•´ë‹¹ ê°„ì„ ì— ì¸ì ‘í•œ face ì¤‘ í•˜ë‚˜ë¼ë„ ê²°ì ˆ(1)ì¸ ê²½ìš° ê°„ì„  ë ˆì´ë¸” 1\n",
    "                    label = 0\n",
    "                    for f_idx in faces_indices:\n",
    "                        if face_labels_arr[f_idx] == 1:\n",
    "                            label = 1\n",
    "                            break\n",
    "                    edge_labels.append(label)\n",
    "                edge_labels = torch.tensor(edge_labels, dtype=torch.long)\n",
    "            else:\n",
    "                # face ë ˆì´ë¸”ì´ ì—†ëŠ” ê²½ìš° (ë¶„í•  ë¼ë²¨ì´ ì—†ìœ¼ë©´ ëª¨ë‘ 0ìœ¼ë¡œ ì²˜ë¦¬)\n",
    "                edge_labels = torch.zeros(len(edges), dtype=torch.long)\n",
    "\n",
    "            # 6. í´ë˜ìŠ¤ ë ˆì´ë¸” (ê²°ì ˆ ìœ ë¬´)\n",
    "            class_label = torch.tensor(self.class_labels[idx], dtype=torch.long)\n",
    "\n",
    "            # ê²°ê³¼ ë°˜í™˜: íŠ¹ì§•, ì´ì›ƒì •ë³´, í´ë˜ìŠ¤ ë ˆì´ë¸”, ê°„ì„  ë ˆì´ë¸”, (í•„ìš”í•˜ë©´ ì›ë³¸ ë©”ì‰¬ ì •ë³´ë„ ë°˜í™˜ ê°€ëŠ¥)\n",
    "            sample = {\n",
    "                'edge_features': edge_features,          # ê³„ì‚°ëœ ê°„ì„  íŠ¹ì§• (E, 5)\n",
    "                'neighbor_index': neighbor_index,        # ì´ì›ƒ ê°„ì„  ì¸ë±ìŠ¤ (E, 4)\n",
    "                'class_label': class_label,              # ì´ì§„ í´ë˜ìŠ¤ ë ˆì´ë¸” (0 or 1)\n",
    "                'edge_labels': edge_labels,              # ê° ê°„ì„ ì— ëŒ€í•œ ë¶„í•  ë ˆì´ë¸” (E,)\n",
    "                'vertices': vertices,                    # (V, 3) ì‹œê°í™”ìš©\n",
    "                'faces': faces                           # (F, 3) ì‹œê°í™”ìš©\n",
    "            }\n",
    "            return sample\n",
    "        except Exception as e:\n",
    "            print(f\"âŒ __getitem__() error at idx {idx}: {e}\")\n",
    "            \n",
    "            return {\n",
    "                'edge_features': torch.empty(0),\n",
    "                'neighbor_index': torch.empty(0, dtype=torch.long),\n",
    "                'class_label': torch.tensor(0, dtype=torch.long),\n",
    "                'edge_labels': torch.empty(0, dtype=torch.long),\n",
    "                'vertices': np.zeros((0, 3)),\n",
    "                'faces': np.zeros((0, 3))\n",
    "            }\n",
    "\n",
    "# ë°ì´í„°ì…‹ ë° ë°ì´í„°ë¡œë” ì´ˆê¸°í™” ì˜ˆì‹œ (íŒŒì¼ ê²½ë¡œëŠ” ì‹¤ì œ ë°ì´í„°ì…‹ì— ë§ê²Œ ìˆ˜ì •í•´ì•¼ í•¨)\n",
    "# ê²½ë¡œ ì„¤ì •\n",
    "data_dir = r\"C:\\Users\\konyang\\Desktop\\MeshCNN_TF\\data\\dataset\\simplified_mesh\"\n",
    "cache_dir = r\"C:\\Users\\konyang\\Desktop\\MeshCNN_TF\\data\\dataset\\cached_mesh\"\n",
    "\n",
    "# Dataset ê°ì²´ ìƒì„± (ìºì‹œ ê²½ë¡œ í¬í•¨)\n",
    "train_dataset = LungNoduleDataset(\n",
    "    data_dir=data_dir,\n",
    "    split='train',\n",
    "    cache_dir=cache_dir\n",
    ")\n",
    "\n",
    "# DataLoader ì„¤ì • (ë³‘ë ¬ ì²˜ë¦¬ ê¶Œì¥)\n",
    "train_loader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=1,\n",
    "    shuffle=True,\n",
    "    num_workers=0,  # âœ… ì›Œì»¤ ë³‘ë ¬ ì²˜ë¦¬ ë„ê¸°\n",
    "    pin_memory=True\n",
    ")\n",
    "\n",
    "# âœ… ê²€ì¦ìš© ë°ì´í„°ì…‹ ìƒì„±\n",
    "val_dataset = LungNoduleDataset(\n",
    "    data_dir=data_dir,\n",
    "    split='val',\n",
    "    cache_dir=cache_dir\n",
    ")\n",
    "\n",
    "val_loader = DataLoader(\n",
    "    val_dataset,\n",
    "    batch_size=1,\n",
    "    shuffle=False,  # ê²€ì¦ì€ shuffleí•˜ì§€ ì•ŠìŒ\n",
    "    num_workers=0,\n",
    "    pin_memory=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d34f4225-68ec-4b26-ad93-6a6a6911b5cf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class MeshConv(nn.Module):\n",
    "    \"\"\"ë©”ì‰¬ ê°„ì„  í•©ì„±ê³± ë ˆì´ì–´: ê° ê°„ì„ ê³¼ ì´ì›ƒí•œ 4ê°œ ê°„ì„  (ì´5ê°œ)ì˜ íŠ¹ì§•ì„ í†µí•©í•´ ì¶œë ¥.\"\"\"\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(MeshConv, self).__init__()\n",
    "        # 5 * in_channels í¬ê¸°ì˜ ì…ë ¥ì„ out_channelsë¡œ ë³€í™˜\n",
    "        self.linear = nn.Linear(in_channels * 5, out_channels)\n",
    "    \n",
    "    def forward(self, x, neighbor_index):\n",
    "        # x: (E, in_channels)\n",
    "        # neighbor_index: (E, 4)\n",
    "\n",
    "        E, in_channels = x.shape\n",
    "        device = x.device\n",
    "\n",
    "        # (E, 1, in_channels): ìê¸° ìì‹ \n",
    "        x_self = x.unsqueeze(1)\n",
    "\n",
    "        # (E, 4) â†’ (E, 4, in_channels): neighbor ì¸ë±ìŠ¤ë¥¼ gatherí•˜ê¸° ìœ„í•´ í™•ì¥\n",
    "        neighbor_index_expanded = neighbor_index.unsqueeze(-1).expand(-1, -1, in_channels)\n",
    "\n",
    "        # x â†’ (1, E, in_channels): gather dim=1ì„ ìœ„í•´ í™•ì¥\n",
    "        x_expanded = x.unsqueeze(0)\n",
    "\n",
    "        # gatherë¥¼ ì‚¬ìš©í•´ neighbor feature ì¶”ì¶œ: (1, E, C)ì—ì„œ gather (E, 4, C)\n",
    "        x_neighbors = torch.gather(x_expanded.expand(E, -1, -1), dim=1, index=neighbor_index_expanded)\n",
    "\n",
    "        # concat: (E, 5, in_channels)\n",
    "        x_combined = torch.cat([x_self, x_neighbors], dim=1)\n",
    "\n",
    "        # Flatten: (E, 5 * in_channels)\n",
    "        x_flat = x_combined.view(E, -1)\n",
    "\n",
    "        out = self.linear(x_flat)\n",
    "        return out  # (E, out_channels)\n",
    "\n",
    "class MeshPool(nn.Module):\n",
    "    \"\"\"ë©”ì‰¬ í’€ë§ ë ˆì´ì–´: ê°„ì„  ìˆ˜ë¥¼ ê°ì†Œ (2:1 ë¹„ìœ¨ë¡œ í´ëŸ¬ìŠ¤í„°).\"\"\"\n",
    "    def __init__(self):\n",
    "        super(MeshPool, self).__init__()\n",
    "        self.cluster_map = None  # ë‚˜ì¤‘ì— unpoolì— ì‚¬ìš©í•˜ê¸° ìœ„í•œ ë§¤í•‘\n",
    "    \n",
    "    def forward(self, x, neighbor_index):\n",
    "        # x: (N, C) ì…ë ¥ ê°„ì„  íŠ¹ì§•, N = í˜„ì¬ ê°„ì„  ìˆ˜\n",
    "        N = x.size(0)\n",
    "        # í´ëŸ¬ìŠ¤í„° êµ¬ì„±: 2ê°œ ê°„ì„ ì”© ë¬¶ìŒ (í™€ìˆ˜ê°œì¼ ê²½ìš° ë§ˆì§€ë§‰ì€ ë‹¨ë… í´ëŸ¬ìŠ¤í„°)\n",
    "        if N % 2 == 0:\n",
    "            new_N = N // 2\n",
    "        else:\n",
    "            new_N = N // 2 + 1\n",
    "        # ì¶œë ¥ í…ì„œ ì´ˆê¸°í™”\n",
    "        device = x.device\n",
    "        C = x.size(1)\n",
    "        x_pooled = torch.zeros((new_N, C), dtype=x.dtype, device=device)\n",
    "        # cluster_map: ê¸¸ì´ N ë¦¬ìŠ¤íŠ¸ë¡œ, ê° ê°„ì„ ì´ ì†í•œ í´ëŸ¬ìŠ¤í„° ì¸ë±ìŠ¤\n",
    "        cluster_map = [-1] * N\n",
    "        # 2ê°œì”© í‰ê· \n",
    "        for i in range(N // 2):\n",
    "            idx1 = 2 * i\n",
    "            idx2 = 2 * i + 1\n",
    "            x_pooled[i] = 0.5 * (x[idx1] + x[idx2])\n",
    "            cluster_map[idx1] = i\n",
    "            cluster_map[idx2] = i\n",
    "        if N % 2 == 1:\n",
    "            # ë§ˆì§€ë§‰ ê°„ì„ ì€ ë‹¨ë… í´ëŸ¬ìŠ¤í„°\n",
    "            x_pooled[new_N - 1] = x[N - 1]\n",
    "            cluster_map[N - 1] = new_N - 1\n",
    "        # cluster_mapì„ Tensorë¡œ ì €ì¥\n",
    "        cluster_map = torch.tensor(cluster_map, dtype=torch.long, device=device)\n",
    "        self.cluster_map = cluster_map\n",
    "        \n",
    "        # ìƒˆë¡œìš´ neighbor_index ê³„ì‚° (í´ëŸ¬ìŠ¤í„° ê·¸ë˜í”„ì˜ ì´ì›ƒ)\n",
    "        neighbors_coarse = []\n",
    "        # ì›ë˜ ê°„ì„ ì˜ neighbor_indexë¡œë¶€í„° í´ëŸ¬ìŠ¤í„° ê°„ ì´ì›ƒì„ ìœ ì¶”\n",
    "        for edge_idx in range(N):\n",
    "            cluster_idx = cluster_map[edge_idx].item()\n",
    "            # ì›ë˜ ê°„ì„ ì˜ ì´ì›ƒë“¤ì˜ í´ëŸ¬ìŠ¤í„° ì¸ë±ìŠ¤\n",
    "            for nbr_edge in neighbor_index[edge_idx]:\n",
    "                nbr_cluster = cluster_map[nbr_edge].item()\n",
    "                if nbr_cluster != cluster_idx:\n",
    "                    # ë¦¬ìŠ¤íŠ¸ ê¸¸ì´ë¥¼ cluster_idxì— ë§ì¶° í™•ì¥\n",
    "                    if cluster_idx >= len(neighbors_coarse):\n",
    "                        neighbors_coarse.extend([set() for _ in range(cluster_idx - len(neighbors_coarse) + 1)])\n",
    "                    neighbors_coarse[cluster_idx].add(nbr_cluster)\n",
    "        # ì§‘í•©ì„ ë¦¬ìŠ¤íŠ¸ë¡œ ë³€í™˜í•˜ê³  4ê°œë¡œ íŒ¨ë”©\n",
    "        for i in range(len(neighbors_coarse)):\n",
    "            nbrs = list(neighbors_coarse[i])\n",
    "            nbrs = nbrs[:4]  # ìµœëŒ€ 4ê°œê¹Œì§€ ì‚¬ìš©\n",
    "            while len(nbrs) < 4:\n",
    "                nbrs.append(i)  # ìê¸° ìì‹ ìœ¼ë¡œ íŒ¨ë”©\n",
    "            neighbors_coarse[i] = nbrs\n",
    "        # ë§Œì•½ ì–´ë–¤ í´ëŸ¬ìŠ¤í„°ì— ëŒ€í•´ neighbor_setì´ ë¹„ì–´ìˆìœ¼ë©´ ìê¸° ìì‹  4ê°œë¡œ\n",
    "        if len(neighbors_coarse) < new_N:\n",
    "            # ë¹ˆ í´ëŸ¬ìŠ¤í„° neighbor ì„¸íŠ¸ ì´ˆê¸°í™”\n",
    "            for i in range(len(neighbors_coarse), new_N):\n",
    "                neighbors_coarse.append([i, i, i, i])\n",
    "        neighbor_index_coarse = torch.tensor(neighbors_coarse, dtype=torch.long, device=device)\n",
    "        \n",
    "        return x_pooled, neighbor_index_coarse\n",
    "\n",
    "class MeshUnpool(nn.Module):\n",
    "    \"\"\"ë©”ì‰¬ ì—…í’€ë§ ë ˆì´ì–´: í’€ë§ëœ ê°„ì„  íŠ¹ì§•ì„ ì›ë˜ ê°œìˆ˜ë¡œ ë³µì›.\"\"\"\n",
    "    def forward(self, x_coarse, cluster_map):\n",
    "        # x_coarse: (M, C) í’€ë§ëœ ê°„ì„  íŠ¹ì§•, cluster_map: (N,) ê° ì›ë˜ ê°„ì„  -> í´ëŸ¬ìŠ¤í„° ì¸ë±ìŠ¤ ë§¤í•‘\n",
    "        device = x_coarse.device\n",
    "        N = cluster_map.shape[0]  # ì›ë˜ ê°„ì„  ê°œìˆ˜\n",
    "        C = x_coarse.shape[1]\n",
    "        # cluster_mapì„ ì´ìš©í•´ ê° ì›ë˜ ê°„ì„ ì˜ íŠ¹ì§• í• ë‹¹\n",
    "        x_reconstructed = torch.zeros((N, C), dtype=x_coarse.dtype, device=device)\n",
    "        # cluster_mapì˜ ê° ì¸ë±ìŠ¤ë¥¼ ìˆœíšŒí•˜ë©° í• ë‹¹\n",
    "        for orig_edge_idx, cluster_idx in enumerate(cluster_map):\n",
    "            x_reconstructed[orig_edge_idx] = x_coarse[cluster_idx]\n",
    "        return x_reconstructed\n",
    "\n",
    "# ì´ì œ Encoder, Decoder, Classifier, Segmenterë¥¼ ì •ì˜\n",
    "class MeshEncoder(nn.Module):\n",
    "    def __init__(self, in_channels=5):\n",
    "        super(MeshEncoder, self).__init__()\n",
    "        # ì±„ë„ ì„¤ì •: conv1_out=16, conv2_out=32, conv3_out=64 (ì˜ˆì‹œ)\n",
    "        self.conv1 = MeshConv(in_channels, 16)\n",
    "        self.pool1 = MeshPool()\n",
    "        self.conv2 = MeshConv(16, 32)\n",
    "        self.pool2 = MeshPool()\n",
    "        self.conv3 = MeshConv(32, 64)\n",
    "    \n",
    "    def forward(self, x, neighbor_index):\n",
    "        # conv1 + ReLU\n",
    "        x1 = F.relu(self.conv1(x, neighbor_index))\n",
    "        # pool1\n",
    "        x_pooled1, neighbor_coarse1 = self.pool1(x1, neighbor_index)\n",
    "        # conv2 + ReLU on pooled1\n",
    "        x2 = F.relu(self.conv2(x_pooled1, neighbor_coarse1))\n",
    "        # pool2\n",
    "        x_pooled2, neighbor_coarse2 = self.pool2(x2, neighbor_coarse1)\n",
    "        # conv3 + ReLU on pooled2 (encoder ìµœì¢…)\n",
    "        x3 = F.relu(self.conv3(x_pooled2, neighbor_coarse2))\n",
    "        # Encoder ê²°ê³¼ì™€ ì¤‘ê°„ ê²°ê³¼ ë°˜í™˜ (ìŠ¤í‚µ ì—°ê²° ë° Decoderì— í•„ìš”)\n",
    "        return {\n",
    "            'x1': x1,                       # original level features (E edges, 16ch)\n",
    "            'neighbor0': neighbor_index, \n",
    "            'x2': x2,                       # half level features (E/2 edges, 32ch)\n",
    "            'neighbor1': neighbor_coarse1,\n",
    "            'x3': x3,                       # quarter level features (E/4 edges, 64ch)\n",
    "            'neighbor2': neighbor_coarse2,\n",
    "            'pool1': self.pool1,\n",
    "            'pool2': self.pool2\n",
    "        }\n",
    "\n",
    "class MeshDecoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MeshDecoder, self).__init__()\n",
    "        self.conv2_up = MeshConv(32 + 64, 32)\n",
    "        self.conv1_up = MeshConv(16 + 32, 16)\n",
    "\n",
    "    def forward(self, enc_out):\n",
    "        x2 = enc_out['x2']\n",
    "        x3 = enc_out['x3']\n",
    "        neighbor1 = enc_out['neighbor1']\n",
    "        neighbor0 = enc_out['neighbor0']\n",
    "        pool1_layer = enc_out['pool1']\n",
    "        pool2_layer = enc_out['pool2']\n",
    "\n",
    "        # Unpool quarter â†’ half\n",
    "        x2_up = MeshUnpool().forward(x3.detach(), pool2_layer.cluster_map)  # (E/2, 64)\n",
    "\n",
    "        # Concat with skip connection\n",
    "        x2_cat = torch.cat([x2.detach(), x2_up], dim=1)  # (E/2, 96)\n",
    "        x2_up_refined = F.relu(self.conv2_up(x2_cat, neighbor1))  # (E/2, 32)\n",
    "\n",
    "        # Unpool half â†’ original\n",
    "        x1_up = MeshUnpool().forward(x2_up_refined.detach(), pool1_layer.cluster_map)  # (E, 32)\n",
    "\n",
    "        x1 = enc_out['x1']\n",
    "        x1_cat = torch.cat([x1.detach(), x1_up], dim=1)  # (E, 48)\n",
    "\n",
    "        x1_up_refined = F.relu(self.conv1_up(x1_cat, neighbor0))  # (E, 16)\n",
    "\n",
    "        return x1_up_refined\n",
    "\n",
    "class ClassificationHead(nn.Module):\n",
    "    def __init__(self, in_channels, hidden_dim=100, num_classes=2):\n",
    "        super(ClassificationHead, self).__init__()\n",
    "        # ë‹¨ìˆœí•œ MLP ë¶„ë¥˜ê¸°: [in_channels] -> [hidden_dim] -> [num_classes]\n",
    "        self.fc1 = nn.Linear(in_channels, hidden_dim)\n",
    "        self.fc2 = nn.Linear(hidden_dim, num_classes)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # x: (in_channels) or (1, in_channels) ì „ì—­ íŠ¹ì§• ë²¡í„°\n",
    "        x = F.relu(self.fc1(x))\n",
    "        out = self.fc2(x)\n",
    "        return out  # raw logits (num_classes)\n",
    "    \n",
    "class SegmentationHead(nn.Module):\n",
    "    def __init__(self, in_channels, num_classes=2):\n",
    "        super(SegmentationHead, self).__init__()\n",
    "        self.linear = nn.Linear(in_channels, num_classes)\n",
    "    def forward(self, x):\n",
    "        # x: (E, in_channels) ëª¨ë“  ì›ë˜ ê°„ì„ ì— ëŒ€í•œ ë³µì›ëœ íŠ¹ì§•\n",
    "        out = self.linear(x)  # (E, num_classes)\n",
    "        return out\n",
    "\n",
    "# ì „ì²´ ëª¨ë¸ í†µí•©\n",
    "class MedMeshNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MedMeshNet, self).__init__()\n",
    "        self.encoder = MeshEncoder(in_channels=5)\n",
    "        self.decoder = MeshDecoder()\n",
    "        # classificationì€ encoder ìµœì¢… ì¶œë ¥ ì±„ë„ (ì˜ˆ: 64)ì„ ë°›ì•„ ì´ì§„ ë¶„ë¥˜\n",
    "        self.classifier = ClassificationHead(in_channels=64, hidden_dim=100, num_classes=2)\n",
    "        # segmentationì€ decoder ìµœì¢… ì¶œë ¥ ì±„ë„ (ì˜ˆ: 16)ì„ ë°›ì•„ 2-class ì¶œë ¥\n",
    "        self.segmenter = SegmentationHead(in_channels=16, num_classes=2)\n",
    "    \n",
    "    def forward(self, edge_features, neighbor_index):\n",
    "        # 1. Encoder: íŠ¹ì§• ì¶”ì¶œ ë° ë‹¤ìš´ìƒ˜í”Œ\n",
    "        enc_out = self.encoder(edge_features, neighbor_index)\n",
    "        # 2. Classification: Encoder ìµœì¢… íŠ¹ì§•ë“¤ì„ ì „ì—­ ìš”ì•½í•˜ì—¬ í´ë˜ìŠ¤ ì˜ˆì¸¡\n",
    "        x_global = torch.max(enc_out['x3'], dim=0)[0]  # ì „ì—­ max í’€ (64ì°¨ì› ë²¡í„°)\n",
    "        class_logits = self.classifier(x_global.unsqueeze(0))  # (1,2) ì¶œë ¥\n",
    "        # 3. Decoder: ì—…ìƒ˜í”Œë¡œ ì›ë˜ í•´ìƒë„ íŠ¹ì§• ë³µì›\n",
    "        dec_out = self.decoder(enc_out)  # (E, 16)\n",
    "        seg_logits = self.segmenter(dec_out)  # (E, 2)\n",
    "        return class_logits, seg_logits\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "070f29ce-e5f9-45d0-a1e7-72073258fd30",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "========== [Epoch 1] ==========\n",
      "244/244 [100%] - 10.2s/step - loss: 0.7902 - acc: 0.6808\n",
      "âœ… Epoch 1 ì™„ë£Œ - í‰ê·  ì†ì‹¤: 0.7902, ì •í™•ë„: 68.08%, ì‹œê°„: 3024.9s\n",
      "70/70 [100%] - 8.3s/step - val_loss: 0.6880 - val_acc: 0.7286\n",
      "ğŸ§ª ê²€ì¦ ì™„ë£Œ - í‰ê·  ì†ì‹¤: 0.6880, ì •í™•ë„: 72.86%, IoU: 0.9941, ì‹œê°„: 790.5s\n",
      "\n",
      "========== [Epoch 2] ==========\n",
      "244/244 [100%] - 10.0s/step - loss: 0.6100 - acc: 0.7183\n",
      "âœ… Epoch 2 ì™„ë£Œ - í‰ê·  ì†ì‹¤: 0.6100, ì •í™•ë„: 71.83%, ì‹œê°„: 3007.7s\n",
      "70/70 [100%] - 8.3s/step - val_loss: 0.6813 - val_acc: 0.7286\n",
      "ğŸ§ª ê²€ì¦ ì™„ë£Œ - í‰ê·  ì†ì‹¤: 0.6813, ì •í™•ë„: 72.86%, IoU: 0.9941, ì‹œê°„: 791.4s\n",
      "\n",
      "========== [Epoch 3] ==========\n",
      "244/244 [100%] - 10.4s/step - loss: 0.5783 - acc: 0.7371\n",
      "âœ… Epoch 3 ì™„ë£Œ - í‰ê·  ì†ì‹¤: 0.5783, ì •í™•ë„: 73.71%, ì‹œê°„: 3014.9s\n",
      "70/70 [100%] - 8.3s/step - val_loss: 0.6613 - val_acc: 0.7286\n",
      "ğŸ§ª ê²€ì¦ ì™„ë£Œ - í‰ê·  ì†ì‹¤: 0.6613, ì •í™•ë„: 72.86%, IoU: 0.9941, ì‹œê°„: 791.5s\n",
      "\n",
      "========== [Epoch 4] ==========\n",
      "243/244 [100%] - 10.4s/step - loss: 0.5837 - acc: 0.7465\n",
      "âœ… Epoch 4 ì™„ë£Œ - í‰ê·  ì†ì‹¤: 0.5837, ì •í™•ë„: 74.65%, ì‹œê°„: 3028.1s\n",
      "70/70 [100%] - 8.3s/step - val_loss: 0.7452 - val_acc: 0.7143\n",
      "ğŸ§ª ê²€ì¦ ì™„ë£Œ - í‰ê·  ì†ì‹¤: 0.7452, ì •í™•ë„: 71.43%, IoU: 0.9941, ì‹œê°„: 791.9s\n",
      "\n",
      "========== [Epoch 5] ==========\n",
      "244/244 [100%] - 11.7s/step - loss: 0.5943 - acc: 0.7418\n",
      "âœ… Epoch 5 ì™„ë£Œ - í‰ê·  ì†ì‹¤: 0.5943, ì •í™•ë„: 74.18%, ì‹œê°„: 3008.4s\n",
      "70/70 [100%] - 8.5s/step - val_loss: 0.6763 - val_acc: 0.7286\n",
      "ğŸ§ª ê²€ì¦ ì™„ë£Œ - í‰ê·  ì†ì‹¤: 0.6763, ì •í™•ë„: 72.86%, IoU: 0.9941, ì‹œê°„: 793.7s\n",
      "\n",
      "========== [Epoch 6] ==========\n",
      "103/244 [42%] - 10.0s/step - loss: 0.4643 - acc: 0.8046\r"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "# ëª¨ë¸ ì´ˆê¸°í™”\n",
    "model = MedMeshNet().to(device)\n",
    "\n",
    "# ì†ì‹¤ í•¨ìˆ˜ ì •ì˜\n",
    "criterion_class = nn.CrossEntropyLoss()\n",
    "class_weights = torch.tensor([1.0, 5.0], device=device)  # âœ… ê²°ì ˆ ê°€ì¤‘ì¹˜ ê°•í™”\n",
    "criterion_seg = nn.CrossEntropyLoss(weight=class_weights)\n",
    "\n",
    "# ì˜µí‹°ë§ˆì´ì € & ìŠ¤ì¼€ì¤„ëŸ¬\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.5)\n",
    "\n",
    "# AMPìš© ìŠ¤ì¼€ì¼ëŸ¬\n",
    "scaler = torch.cuda.amp.GradScaler()\n",
    "\n",
    "# ê²€ì¦ìš© val_loader ì¡´ì¬ í™•ì¸\n",
    "try:\n",
    "    val_loader\n",
    "except NameError:\n",
    "    val_loader = None\n",
    "\n",
    "# ---------------------------\n",
    "# AMP ì ìš© í•™ìŠµ ë£¨í”„ ì‹œì‘\n",
    "# ---------------------------\n",
    "num_epochs = 10\n",
    "total_steps = len(train_loader)\n",
    "val_steps = len(val_loader)\n",
    "\n",
    "for epoch in range(1, num_epochs + 1):\n",
    "    model.train()\n",
    "    total_loss = 0.0\n",
    "    correct_train = 0\n",
    "    total_train = 0\n",
    "    print(f\"\\n========== [Epoch {epoch}] ==========\")\n",
    "\n",
    "    start_time = time.time()\n",
    "\n",
    "    for i, batch in enumerate(train_loader):\n",
    "        step_start = time.time()\n",
    "\n",
    "        features = batch['edge_features'].to(device).squeeze(0)\n",
    "        if features.numel() == 0:\n",
    "            continue\n",
    "\n",
    "        neighbor_index = batch['neighbor_index'].to(device).squeeze(0)\n",
    "        class_label = batch['class_label'].to(device)\n",
    "        seg_label = batch['edge_labels'].to(device).squeeze(0)\n",
    "\n",
    "        if features.shape[0] > 25000:\n",
    "            continue\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        with torch.cuda.amp.autocast():\n",
    "            class_logits, seg_logits = model(features, neighbor_index)\n",
    "            loss_class = criterion_class(class_logits, class_label)\n",
    "            loss_seg = criterion_seg(seg_logits, seg_label)\n",
    "            loss = loss_class + loss_seg\n",
    "\n",
    "        scaler.scale(loss).backward()\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "        pred_class = torch.argmax(class_logits, dim=1)\n",
    "        correct_train += (pred_class == class_label).sum().item()\n",
    "        total_train += class_label.size(0)\n",
    "\n",
    "        # Keras-style ì¶œë ¥\n",
    "        avg_loss = total_loss / (i + 1)\n",
    "        train_acc = correct_train / total_train if total_train > 0 else 0\n",
    "        elapsed = time.time() - step_start\n",
    "        print(f\"{i+1}/{total_steps} [{(i+1)/total_steps:.0%}] - {elapsed:.1f}s/step - loss: {avg_loss:.4f} - acc: {train_acc:.4f}\", end=\"\\r\")\n",
    "\n",
    "    total_elapsed = time.time() - start_time\n",
    "    print(f\"\\nâœ… Epoch {epoch} ì™„ë£Œ - í‰ê·  ì†ì‹¤: {avg_loss:.4f}, ì •í™•ë„: {train_acc*100:.2f}%, ì‹œê°„: {total_elapsed:.1f}s\")\n",
    "\n",
    "    scheduler.step()\n",
    "\n",
    "    # ---------------------------\n",
    "    # ê²€ì¦ ë‹¨ê³„ (no_gradë§Œ ì‚¬ìš©)\n",
    "    # ---------------------------\n",
    "    if val_loader is not None:\n",
    "        model.eval()\n",
    "        correct = 0\n",
    "        total_samples = 0\n",
    "        inter = 0\n",
    "        union = 0\n",
    "        val_loss = 0.0\n",
    "        val_start = time.time()\n",
    "\n",
    "        for j, batch in enumerate(val_loader):\n",
    "            step_start = time.time()\n",
    "\n",
    "            features = batch['edge_features'].to(device).squeeze(0)\n",
    "            if features.numel() == 0:\n",
    "                continue\n",
    "            neighbor_index = batch['neighbor_index'].to(device).squeeze(0)\n",
    "            class_label = batch['class_label'].to(device)\n",
    "            seg_label = batch['edge_labels'].to(device).squeeze(0)\n",
    "\n",
    "            with torch.no_grad():\n",
    "                class_logits, seg_logits = model(features, neighbor_index)\n",
    "                loss_class = criterion_class(class_logits, class_label)\n",
    "                loss_seg = criterion_seg(seg_logits, seg_label)\n",
    "                loss = loss_class + loss_seg\n",
    "                val_loss += loss.item()\n",
    "\n",
    "                pred_class = torch.argmax(class_logits, dim=1)\n",
    "                correct += (pred_class == class_label).sum().item()\n",
    "                total_samples += class_label.size(0)\n",
    "\n",
    "                pred_seg = torch.argmax(seg_logits, dim=1)\n",
    "                num_classes = seg_logits.shape[1]\n",
    "                for cls in range(num_classes):\n",
    "                    inter += ((pred_seg == cls) & (seg_label == cls)).sum().item()\n",
    "                    union += ((pred_seg == cls) | (seg_label == cls)).sum().item()\n",
    "\n",
    "            # ì‹¤ì‹œê°„ ì¶œë ¥\n",
    "            avg_vloss = val_loss / (j + 1)\n",
    "            val_acc = correct / total_samples if total_samples > 0 else 0\n",
    "            elapsed = time.time() - step_start\n",
    "            print(f\"{j+1}/{val_steps} [{(j+1)/val_steps:.0%}] - {elapsed:.1f}s/step - val_loss: {avg_vloss:.4f} - val_acc: {val_acc:.4f}\", end='\\r')\n",
    "\n",
    "        val_elapsed = time.time() - val_start\n",
    "        val_acc = correct / total_samples if total_samples > 0 else 0\n",
    "        val_iou = inter / (union + 1e-8) if union > 0 else 0\n",
    "        print(f\"\\nğŸ§ª ê²€ì¦ ì™„ë£Œ - í‰ê·  ì†ì‹¤: {avg_vloss:.4f}, ì •í™•ë„: {val_acc * 100:.2f}%, IoU: {val_iou:.4f}, ì‹œê°„: {val_elapsed:.1f}s\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f193d949-6b61-454f-8bb8-eaf9e7214ca8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_classification_accuracy(model, data_loader):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for batch in data_loader:\n",
    "            features = batch['edge_features'].to(device)\n",
    "            neighbor_index = batch['neighbor_index'].to(device)\n",
    "            labels = batch['class_label'].to(device)\n",
    "            class_logits, _ = model(features, neighbor_index)\n",
    "            pred = torch.argmax(class_logits, dim=1)  # ì˜ˆì¸¡ í´ë˜ìŠ¤\n",
    "            if pred.item() == labels.item():\n",
    "                correct += 1\n",
    "            total += 1\n",
    "    acc = correct / total if total > 0 else 0\n",
    "    return acc\n",
    "\n",
    "def compute_segmentation_iou(model, data_loader):\n",
    "    model.eval()\n",
    "    inter = 0\n",
    "    union = 0\n",
    "    with torch.no_grad():\n",
    "        for batch in data_loader:\n",
    "            features = batch['edge_features'].to(device)\n",
    "            neighbor_index = batch['neighbor_index'].to(device)\n",
    "            true_seg = batch['edge_labels'].to(device)\n",
    "            _, seg_logits = model(features, neighbor_index)\n",
    "            pred_seg = torch.argmax(seg_logits, dim=1)\n",
    "            # ê²°ì ˆ í´ë˜ìŠ¤(1)ì— ëŒ€í•œ IoU ê³„ì‚°\n",
    "            inter += torch.logical_and(pred_seg == 1, true_seg == 1).sum().item()\n",
    "            union += torch.logical_or(pred_seg == 1, true_seg == 1).sum().item()\n",
    "    iou = inter / (union + 1e-8) if union > 0 else 0\n",
    "    return iou\n",
    "\n",
    "# ì˜ˆì‹œ: í•™ìŠµ ì™„ë£Œ í›„ í…ŒìŠ¤íŠ¸ ì„¸íŠ¸ì— ëŒ€í•œ ì„±ëŠ¥ ì¸¡ì •\n",
    "\n",
    "test_acc = compute_classification_accuracy(model, test_loader)\n",
    "test_iou = compute_segmentation_iou(model, test_loader)\n",
    "print(f\"í…ŒìŠ¤íŠ¸ ì •í™•ë„: {test_acc:.4f}, í…ŒìŠ¤íŠ¸ IoU: {test_iou:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "530f305c-f902-4695-ace0-43183cb78971",
   "metadata": {},
   "outputs": [],
   "source": [
    "import open3d as o3d\n",
    "import trimesh\n",
    "import numpy as np\n",
    "import torch\n",
    "import os\n",
    "\n",
    "# âœ… ëª¨ë¸ ì¤€ë¹„\n",
    "model.eval()\n",
    "\n",
    "# âœ… íŒŒì¼ ì´ë¦„ ì§€ì •\n",
    "target_filename = \"A0173_abnormal.obj\"\n",
    "\n",
    "# âœ… ê²½ë¡œ ì„¤ì •\n",
    "original_mesh_dir = r\"C:\\Users\\konyang\\Desktop\\MeshCNN_TF\\data\\dataset\\mesh\"\n",
    "cache_dir = r\"C:\\Users\\konyang\\Desktop\\MeshCNN_TF\\data\\dataset\\cached_mesh\\train\"\n",
    "npz_path = os.path.join(cache_dir, target_filename.replace(\".obj\", \".npz\"))\n",
    "\n",
    "# âœ… ìºì‹œëœ íŠ¹ì§• ë¶ˆëŸ¬ì˜¤ê¸°\n",
    "if not os.path.exists(npz_path):\n",
    "    raise FileNotFoundError(f\"{npz_path} ìºì‹œ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.\")\n",
    "\n",
    "data = np.load(npz_path)\n",
    "vertices = data['vertices']\n",
    "faces = data['faces']\n",
    "face_normals = data['face_normals']\n",
    "\n",
    "# âœ… ê°„ì„  ë° ì´ì›ƒ ì¸ë±ìŠ¤ ê³„ì‚°\n",
    "edge_to_faces = {}\n",
    "for f_idx, face in enumerate(faces):\n",
    "    for e in [(face[0], face[1]), (face[1], face[2]), (face[2], face[0])]:\n",
    "        e_sorted = tuple(sorted(e))\n",
    "        edge_to_faces.setdefault(e_sorted, []).append(f_idx)\n",
    "edges = list(edge_to_faces.keys())\n",
    "\n",
    "# ì´ì›ƒ ì¸ë±ìŠ¤ ê³„ì‚°\n",
    "vert_to_edges = {v: [] for v in range(len(vertices))}\n",
    "for e_idx, (v1, v2) in enumerate(edges):\n",
    "    vert_to_edges[v1].append(e_idx)\n",
    "    vert_to_edges[v2].append(e_idx)\n",
    "\n",
    "neighbors_list = []\n",
    "for e_idx, (v1, v2) in enumerate(edges):\n",
    "    neighbor_set = set(vert_to_edges[v1] + vert_to_edges[v2])\n",
    "    neighbor_set.discard(e_idx)\n",
    "    neighbors = list(neighbor_set)[:4]\n",
    "    while len(neighbors) < 4:\n",
    "        neighbors.append(e_idx)\n",
    "    neighbors_list.append(neighbors)\n",
    "\n",
    "neighbor_index = torch.tensor(neighbors_list, dtype=torch.long)\n",
    "\n",
    "# ê°„ì„  íŠ¹ì§• ê³„ì‚°\n",
    "edge_features = []\n",
    "for e_idx, (v1, v2) in enumerate(edges):\n",
    "    p1, p2 = vertices[v1], vertices[v2]\n",
    "    edge_length = np.linalg.norm(p1 - p2)\n",
    "    faces_indices = edge_to_faces[(v1, v2)]\n",
    "    if len(faces_indices) == 2:\n",
    "        f1, f2 = faces_indices[0], faces_indices[1]\n",
    "        n1, n2 = face_normals[f1], face_normals[f2]\n",
    "        cos_theta = np.dot(n1, n2) / (np.linalg.norm(n1)*np.linalg.norm(n2) + 1e-8)\n",
    "        dihedral = np.arccos(np.clip(cos_theta, -1.0, 1.0))\n",
    "    else:\n",
    "        dihedral = 0.0\n",
    "\n",
    "    def compute_inner_ratio(f_idx):\n",
    "        face_v = faces[f_idx]\n",
    "        opp_v = [v for v in face_v if v not in (v1, v2)][0]\n",
    "        vec1 = vertices[v1] - vertices[opp_v]\n",
    "        vec2 = vertices[v2] - vertices[opp_v]\n",
    "        cos_inner = np.dot(vec1, vec2) / (np.linalg.norm(vec1)*np.linalg.norm(vec2) + 1e-8)\n",
    "        inner = np.arccos(np.clip(cos_inner, -1.0, 1.0))\n",
    "        area = np.linalg.norm(np.cross(vec1, vec2)) / 2.0\n",
    "        height = (2.0 * area) / (edge_length + 1e-8)\n",
    "        ratio = edge_length / (height + 1e-8)\n",
    "        return inner, ratio\n",
    "\n",
    "    inner1, ratio1 = compute_inner_ratio(faces_indices[0]) if faces_indices else (0.0, 0.0)\n",
    "    inner2, ratio2 = compute_inner_ratio(faces_indices[1]) if len(faces_indices) == 2 else (inner1, ratio1)\n",
    "\n",
    "    edge_features.append([dihedral, inner1, inner2, ratio1, ratio2])\n",
    "\n",
    "edge_features = torch.tensor(edge_features, dtype=torch.float32)\n",
    "\n",
    "# âœ… ëª¨ë¸ ì˜ˆì¸¡\n",
    "edge_features = edge_features.to(device)\n",
    "neighbor_index = neighbor_index.to(device)\n",
    "with torch.no_grad():\n",
    "    class_logits, seg_logits = model(edge_features, neighbor_index)\n",
    "    pred_class = torch.argmax(class_logits, dim=1).item()\n",
    "    pred_seg = torch.argmax(seg_logits, dim=1).cpu().numpy()\n",
    "\n",
    "print(\"ëª¨ë¸ ì˜ˆì¸¡:\", \"í ê²°ì ˆ ìˆìŒ\" if pred_class == 1 else \"ê²°ì ˆ ì—†ìŒ\")\n",
    "\n",
    "# âœ… ê²°ì ˆë¡œ ì˜ˆì¸¡ëœ face ì¶”ì¶œ\n",
    "pred_nodule_faces = set()\n",
    "for e_idx, edge in enumerate(edges):\n",
    "    if pred_seg[e_idx] == 1:\n",
    "        for f_idx in edge_to_faces[edge]:\n",
    "            pred_nodule_faces.add(f_idx)\n",
    "\n",
    "pred_nodule_faces = list(pred_nodule_faces)\n",
    "print(f\"ì˜ˆì¸¡ëœ ê²°ì ˆ ì˜ì—­ ë©´ ê°œìˆ˜: {len(pred_nodule_faces)}ê°œ\")\n",
    "\n",
    "# âœ… ì›ë³¸ ë©”ì‰¬ ë¡œë“œ (ê³ í•´ìƒë„ obj)\n",
    "obj_path = os.path.join(original_mesh_dir, target_filename)\n",
    "tm = trimesh.load(obj_path)\n",
    "vertices = np.array(tm.vertices)\n",
    "faces = np.array(tm.faces)\n",
    "\n",
    "# í•˜ì´ë¼ì´íŠ¸í•  ì •ì \n",
    "highlighted_vertices = set()\n",
    "for f_idx in pred_nodule_faces:\n",
    "    if f_idx < len(faces):\n",
    "        highlighted_vertices.update(faces[f_idx])\n",
    "\n",
    "# ìƒ‰ìƒ í• ë‹¹\n",
    "colors = np.tile([0.7, 0.7, 0.7], (len(vertices), 1))  # íšŒìƒ‰\n",
    "for v in highlighted_vertices:\n",
    "    if v < len(colors):\n",
    "        colors[v] = [1.0, 0.0, 0.0]  # ë¹¨ê°•\n",
    "\n",
    "# Open3D ë©”ì‰¬ ë³€í™˜\n",
    "mesh_o3d = o3d.geometry.TriangleMesh()\n",
    "mesh_o3d.vertices = o3d.utility.Vector3dVector(vertices)\n",
    "mesh_o3d.triangles = o3d.utility.Vector3iVector(faces)\n",
    "mesh_o3d.vertex_colors = o3d.utility.Vector3dVector(colors)\n",
    "mesh_o3d.compute_vertex_normals()\n",
    "\n",
    "# âœ… ì‹œê°í™”\n",
    "o3d.visualization.draw_geometries([mesh_o3d], window_name=\"ê²°ì ˆ ì˜ˆì¸¡ ì‹œê°í™”\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d9d1710-b128-46d1-9e51-cf9d9bb14d73",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from sklearn.metrics import classification_report, confusion_matrix, jaccard_score, accuracy_score\n",
    "\n",
    "def evaluate_model(model, dataloader, device='cuda'):\n",
    "    model.eval()\n",
    "    \n",
    "    all_preds_cls = []\n",
    "    all_labels_cls = []\n",
    "\n",
    "    all_preds_seg = []\n",
    "    all_labels_seg = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in dataloader:\n",
    "            features = batch['edge_features'].to(device).squeeze(0)\n",
    "            neighbor_index = batch['neighbor_index'].to(device).squeeze(0)\n",
    "            class_label = batch['class_label'].to(device)\n",
    "            seg_label = batch['edge_labels'].to(device).squeeze(0)\n",
    "\n",
    "            if features.numel() == 0 or features.shape[0] > 25000:\n",
    "                continue\n",
    "\n",
    "            class_logits, seg_logits = model(features, neighbor_index)\n",
    "\n",
    "            # âœ… ë¶„ë¥˜ ê²°ê³¼\n",
    "            pred_class = torch.argmax(class_logits, dim=1)\n",
    "            all_preds_cls.extend(pred_class.cpu().numpy())\n",
    "            all_labels_cls.extend(class_label.cpu().numpy())\n",
    "\n",
    "            # âœ… ì„¸ë¶„í™” ê²°ê³¼\n",
    "            pred_seg = torch.argmax(seg_logits, dim=1)\n",
    "            all_preds_seg.extend(pred_seg.cpu().numpy())\n",
    "            all_labels_seg.extend(seg_label.cpu().numpy())\n",
    "\n",
    "    # â–¶ Classification ì„±ëŠ¥\n",
    "    print(\"ğŸ” [Classification Results]\")\n",
    "    print(classification_report(all_labels_cls, all_preds_cls, target_names=[\"Normal\", \"Nodule\"]))\n",
    "    print(\"Confusion Matrix:\\n\", confusion_matrix(all_labels_cls, all_preds_cls))\n",
    "\n",
    "    # â–¶ Segmentation ì„±ëŠ¥ (IoU, ì •í™•ë„)\n",
    "    print(\"\\nğŸ” [Segmentation Results]\")\n",
    "    acc_seg = accuracy_score(all_labels_seg, all_preds_seg)\n",
    "    iou_seg = jaccard_score(all_labels_seg, all_preds_seg, average='binary')\n",
    "    print(f\"Segmentation Accuracy: {acc_seg * 100:.2f}%\")\n",
    "    print(f\"Segmentation IoU: {iou_seg:.4f}\")\n",
    "\n",
    "evaluate_model(model, val_loader, device=device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1b85ce8-df33-4b59-bebb-25f16c2d043f",
   "metadata": {},
   "source": [
    "í•˜ì´í¼íŒŒë¼ë¯¸í„° ì¡°ì •, ë°ì´í„° ì¦ê°•, í‰ê°€ ì§€í‘œ ì¶”ê°€ ë° ìµœì í™” ë“± ì¶”ê°€ ì‘ì—… í•„ìš”"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "project2025",
   "language": "python",
   "name": "project2025"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
